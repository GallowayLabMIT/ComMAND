{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rushd as rd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "\n",
    "# enables concurrent editing of base.py\n",
    "from importlib import reload\n",
    "reload(base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Circuit tuning data (`data`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = rd.datadir/'instruments'/'data'/'attune'/'kasey'\n",
    "\n",
    "exp90_path = base_path/'2024.03.31_exp90'/'export'\n",
    "exp90_2_path = base_path/'2024.04.02_exp90.2'/'export'\n",
    "exp90_3_path = base_path/'2024.04.02_exp90.3'/'export'\n",
    "exp90_4_path = base_path/'2024.04.05_exp90.4'/'export'\n",
    "exp91_path = base_path/'2024.04.08_exp91'/'export'\n",
    "exp92_path = base_path/'2024.04.12_exp92'/'export'\n",
    "\n",
    "plates = pd.DataFrame({\n",
    "    'data_path': [exp90_path/'plate1', exp90_path/'plate2', \n",
    "                  exp90_2_path, exp90_4_path,\n",
    "                  exp90_3_path/'plate1', exp90_3_path/'plate2', \n",
    "                  exp91_path/'plate1.1', exp91_path/'plate1.2', exp91_path/'plate1.3', \n",
    "                  exp91_path/'plate2.1', exp91_path/'plate2.2', exp91_path/'plate2.3',\n",
    "                  exp92_path/'plate1.1', exp92_path/'plate1.2', exp92_path/'plate1.3', \n",
    "                  exp92_path/'plate2.1', exp92_path/'plate2.2', exp92_path/'plate2.3',],\n",
    "    \n",
    "    'yaml_path': ([exp90_path/'exp90_plate1_wells.yaml', exp90_path/'exp90_plate2_wells.yaml', \n",
    "                   exp90_path/'exp90_plate2_wells.yaml', exp90_path/'exp90_plate1_wells.yaml',\n",
    "                   exp90_path/'exp90_plate1_wells.yaml', exp90_path/'exp90_plate2_wells.yaml', ] +\n",
    "                  [exp91_path/'exp91_plate1_wells.yaml']*3 + \n",
    "                  [exp91_path/'exp91_plate2.1_wells.yaml', exp91_path/'exp91_plate2.2_wells.yaml', exp91_path/'exp91_plate2.3_wells.yaml'] +\n",
    "                  [exp92_path/'exp92_plate1_wells.yaml', exp92_path/'exp92_plate1.2_wells.yaml', exp92_path/'exp92_plate1_wells.yaml',\n",
    "                   exp92_path/'exp92_plate2_wells.yaml', exp92_path/'exp92_plate2.2_wells.yaml', exp92_path/'exp92_plate2_wells.yaml',]\n",
    "                  ),\n",
    "    \n",
    "    'biorep': ([1, 1, \n",
    "                2, 2, \n",
    "                3, 3,] + \n",
    "                [1, 2, 3,]*4),\n",
    "    \n",
    "    'exp': (['exp90', 'exp90', \n",
    "             'exp90.2', 'exp90.4', \n",
    "             'exp90.3', 'exp90.3',] + \n",
    "            ['exp91']*6 + \n",
    "            ['exp92']*6)\n",
    "})\n",
    "\n",
    "output_path = rd.rootdir/'output'/'fig_designs'\n",
    "cache_path = rd.rootdir/'output'/'fig_overview'/'data.gzip'\n",
    "metadata_path = rd.datadir/'projects'/'miR-iFFL'/'plasmids'/'construct-metadata.xlsx'\n",
    "\n",
    "# Load data\n",
    "data = pd.DataFrame()\n",
    "if cache_path.is_file(): data = pd.read_parquet(cache_path)\n",
    "else: \n",
    "    channel_list = ['mCherry-A','mRuby2-A','FSC-A','SSC-A','tagBFP-A','mGL-A']\n",
    "    data = rd.flow.load_groups_with_metadata(plates, columns=channel_list)\n",
    "\n",
    "    # Remove negative channel values\n",
    "    for c in channel_list: data = data[data[c]>0]\n",
    "    \n",
    "    data.dropna(inplace=True)\n",
    "    data.to_parquet(rd.outfile(cache_path))\n",
    "\n",
    "# Add metadata for constructs\n",
    "metadata = base.get_metadata(metadata_path, style='designs')\n",
    "data = data.merge(metadata, how='left', on='construct')\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dicts to specify colors/markers\n",
    "metadata_dict = metadata.set_index('construct').to_dict('dict')\n",
    "designs_palette = metadata_dict['color']\n",
    "designs_markers = metadata_dict['markers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gate cells\n",
    "gates = pd.DataFrame()\n",
    "channel_list = ['mGL-A', 'mRuby2-A']\n",
    "for channel in channel_list:\n",
    "    gates[channel] = data[data['construct']=='UT'].groupby(['exp'])[channel].apply(lambda x: x.quantile(0.999))\n",
    "gates.reset_index(inplace=True)\n",
    "\n",
    "# Add missing gates\n",
    "gates.loc[len(gates.index)] = ['exp90.4',0,0,]  \n",
    "gates.loc[gates['exp']=='exp90.4', channel_list] = gates.loc[gates['exp']=='exp90.2', channel_list].values\n",
    "\n",
    "# Indicate which channels are relevant for each experiment\n",
    "gates.sort_values(['exp'], inplace=True)\n",
    "gates['marker'] = 'mGL-A'\n",
    "gates['output'] = 'mRuby2-A'\n",
    "\n",
    "# Gate data by transfection marker expression\n",
    "data = data.groupby('exp')[data.columns].apply(lambda x: base.gate_data(x,gates))\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "df = data[(data['expressing']) & (data['construct']!='UT') & (data['exp']!='elp_exp61')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin data and calculate statistics\n",
    "df_quantiles, stats, _, fits = base.calculate_bins_stats(df, num_bins=20)\n",
    "stats = stats.merge(metadata, how='left', on='construct')\n",
    "fits = fits.merge(metadata, how='left', on='construct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_label = {'na': 'base', 'NT': 'OL', 'T': 'CL', 'none': 'â€“'}\n",
    "metadata['ts_label'] = metadata['ts_kind'].replace(ts_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load PiggyBac data (`data_pb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_path = base_path/'2023.07.18_exp63.3-RC'/'export'\n",
    "\n",
    "plates = pd.DataFrame({\n",
    "    'data_path': [pb_path],\n",
    "    \n",
    "    'yaml_path': [pb_path/'exp63.3_wells2.yaml'],\n",
    "    \n",
    "    'biorep': [1],\n",
    "    \n",
    "    'exp': ['exp63.3-RC']\n",
    "})\n",
    "\n",
    "cache_path = rd.rootdir/'output'/'fig_designs'/'data_pb.gzip'\n",
    "\n",
    "# Load data\n",
    "data_pb = pd.DataFrame()\n",
    "if cache_path.is_file(): data_pb = pd.read_parquet(cache_path)\n",
    "else: \n",
    "    channel_list = ['mCherry-A','mRuby2-A','FSC-A','SSC-A','tagBFP-A','mGL-A']\n",
    "    data_pb = rd.flow.load_groups_with_metadata(plates, columns=channel_list)\n",
    "\n",
    "    # Remove negative channel values\n",
    "    for c in channel_list: data_pb = data_pb[data_pb[c]>0]\n",
    "    \n",
    "    data_pb.dropna(inplace=True)\n",
    "    data_pb.to_parquet(rd.outfile(cache_path))\n",
    "\n",
    "# Add metadata for constructs\n",
    "data_pb = data_pb.merge(metadata, how='left', on='construct')\n",
    "display(data_pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gate cells\n",
    "# Add missing gates (use gates from tuning exp)\n",
    "channel_list = ['mGL-A', 'mRuby2-A']\n",
    "gates.loc[len(gates.index)] = ['exp63.3-RC'] + list(gates.loc[gates['exp']!='exp63.3-RC', channel_list].mean().values) + ['mGL-A','mRuby2-A']  \n",
    "\n",
    "# Gate data by transfection marker expression\n",
    "data_pb = data_pb.groupby('exp')[data_pb.columns].apply(lambda x: base.gate_data(x,gates))\n",
    "data_pb.reset_index(inplace=True, drop=True)\n",
    "df_pb = data_pb[(data_pb['expressing']) & (data_pb['construct']!='UT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin data and calculate statistics\n",
    "df_quantiles_pb, stats_pb, _, fits_pb = base.calculate_bins_stats(df_pb, num_bins=20)\n",
    "stats_pb = stats_pb.merge(metadata, how='left', on='construct')\n",
    "fits_pb = fits_pb.merge(metadata, how='left', on='construct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from 293T, MEF lenti infections (`data_lenti`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_1 = rd.datadir/'instruments'/'data'/'attune'/'kasey'/'2024.04.05_exp89'/'export'\n",
    "base_path_2 = rd.datadir/'instruments'/'data'/'attune'/'chris'/'2024.06.02-exp95-lenti-miR-iFFL'/'export'\n",
    "plate_list = ['_'.join(x) for x in zip(\n",
    "        ['plate'+str(i) for i in range(1,10)], \n",
    "        (['293T']*3 + ['MEF2A']*3 + ['MEF8A']*3),\n",
    "        ['P9','P14','P15']*3\n",
    "    )]\n",
    "\n",
    "plates = pd.DataFrame({\n",
    "    'data_path': [base_path_1/'293T_control', \n",
    "                  base_path_1/'293T_plate1', base_path_1/'293T_plate2', base_path_1/'293T_plate3',\n",
    "                  base_path_1/'MEF_3_plate1', \n",
    "                  base_path_1/'MEF_4-1_plate1', base_path_1/'MEF_4-1_plate2', base_path_1/'MEF_4-1_plate3'] +\n",
    "                 [base_path_2/p for p in plate_list],\n",
    "    'yaml_path': [base_path_1/'kasey_yaml2'/'plate_control.yaml', \n",
    "                  base_path_1/'kasey_yaml2'/'plate01.yaml', base_path_1/'kasey_yaml2'/'plate02.yaml', base_path_1/'kasey_yaml2'/'plate03.yaml',\n",
    "                  base_path_1/'kasey_yaml2'/'mef_3_plate01.yaml', \n",
    "                  base_path_1/'kasey_yaml2'/'mef_4-1_plate01.yaml', base_path_1/'kasey_yaml2'/'mef_4-1_plate02.yaml', base_path_1/'kasey_yaml2'/'mef_4-1_plate03.yaml'] +\n",
    "                 [base_path_2/(p+'_metadata.yaml') for p in plate_list],\n",
    "})\n",
    "\n",
    "cache_path = output_path/'data_lenti.gzip'\n",
    "metadata_path = rd.datadir/'projects'/'miR-iFFL'/'plasmids'/'construct-metadata.xlsx'\n",
    "\n",
    "# Load data\n",
    "data_lenti = pd.DataFrame()\n",
    "if cache_path.is_file(): data_lenti = pd.read_parquet(cache_path)\n",
    "else: \n",
    "    channel_list = ['mCherry-A','mRuby2-A','FSC-A','SSC-A','tagBFP-A','mGL-A']\n",
    "    data_lenti = rd.flow.load_groups_with_metadata(plates, columns=channel_list)\n",
    "\n",
    "    # Remove negative channel values\n",
    "    for c in channel_list: data_lenti = data_lenti[data_lenti[c]>0]\n",
    "    \n",
    "    #data.dropna(inplace=True)\n",
    "    data_lenti.to_parquet(rd.outfile(cache_path))\n",
    "\n",
    "# Add metadata for constructs\n",
    "data_lenti = data_lenti.merge(metadata, how='left', on='construct')\n",
    "data_lenti['cell'] = data_lenti['cell_type'].apply(lambda x: x.split('-')[0])\n",
    "data_lenti['exp'] = data_lenti['cell_type'] + '_' + data_lenti['virus_batch']\n",
    "\n",
    "def map_biorep(df):\n",
    "    biorep_map = {val:i for i,val in enumerate(df['exp'].unique())}\n",
    "    d = df.copy()\n",
    "    d['biorep'] = d['exp'].map(biorep_map)\n",
    "    return d\n",
    "\n",
    "data_lenti = data_lenti.groupby('cell')[data_lenti.columns].apply(map_biorep).reset_index(drop=True)\n",
    "display(data_lenti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gate cells\n",
    "gates_lenti = pd.DataFrame()\n",
    "channel_list = ['mGL-A', 'mCherry-A', 'mRuby2-A']\n",
    "for channel in channel_list:\n",
    "    gates_lenti[channel] = data_lenti[(data_lenti['virus_dilution']==0)].groupby(['exp'])[channel].apply(lambda x: x.quantile(0.999))\n",
    "gates_lenti.reset_index(inplace=True)\n",
    "\n",
    "# Add missing gates\n",
    "gates_lenti.loc[len(gates_lenti.index)] = ['293T_P10'] + list(gates_lenti.loc[gates_lenti['exp']=='293T_na', channel_list].mean().values)\n",
    "gates_lenti.loc[len(gates_lenti.index)] = ['293T_P14_'] + list(gates_lenti.loc[gates_lenti['exp']=='293T_na', channel_list].mean().values)\n",
    "gates_lenti.loc[len(gates_lenti.index)] = ['293T_P16'] + list(gates_lenti.loc[gates_lenti['exp']=='293T_na', channel_list].mean().values) \n",
    "gates_lenti.loc[len(gates_lenti.index)] = ['MEF-3_P10'] + list(gates_lenti.loc[gates_lenti['exp'].str.contains('MEF'), channel_list].mean().values)\n",
    "gates_lenti.loc[len(gates_lenti.index)] = ['MEF-4-1_P10'] + list(gates_lenti.loc[gates_lenti['exp'].str.contains('MEF'), channel_list].mean().values)\n",
    "gates_lenti.loc[len(gates_lenti.index)] = ['MEF-4-1_P14'] + list(gates_lenti.loc[gates_lenti['exp'].str.contains('MEF'), channel_list].mean().values)\n",
    "gates_lenti.loc[len(gates_lenti.index)] = ['MEF-4-1_P16'] + list(gates_lenti.loc[gates_lenti['exp'].str.contains('MEF'), channel_list].mean().values)\n",
    "\n",
    "# Indicate which channels are relevant for each experiment\n",
    "gates_lenti.sort_values(['exp'], inplace=True)\n",
    "gates_lenti['marker'] = 'mGL-A'\n",
    "gates_lenti['output'] = 'mRuby2-A'\n",
    "\n",
    "# Gate data by marker expression\n",
    "data_lenti = data_lenti.groupby(['cell_type','virus_batch'])[data_lenti.columns].apply(lambda x: base.gate_data(x,gates_lenti))\n",
    "data_lenti.reset_index(inplace=True, drop=True)\n",
    "df_lenti = data_lenti[(data_lenti['expressing']) & (data_lenti['virus_dilution']!=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin data and calculate statistics\n",
    "df_lenti['output'] = df_lenti['output'].astype(float)\n",
    "df_lenti['marker'] = df_lenti['marker'].astype(float)\n",
    "df_quantiles_lenti, stats_lenti, _, fits_lenti = base.calculate_bins_stats(df_lenti, by=['exp','cell','biorep','construct','dox','virus_dilution'], num_bins=20)\n",
    "stats_lenti = stats_lenti.merge(metadata, how='left', on='construct')\n",
    "fits_lenti = fits_lenti.merge(metadata, how='left', on='construct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_size = base.font_sizes['base_size']\n",
    "smaller_size = base.font_sizes['smaller_size']\n",
    "\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('paper', font_scale=1.0, rc={'font.size': base_size, 'font.family': 'sans-serif', 'font.sans-serif':['Arial']})\n",
    "plt.rcParams.update({'axes.titlesize': base_size, 'axes.labelsize': base_size, 'xtick.labelsize': smaller_size, 'ytick.labelsize': smaller_size,\n",
    "                     'pdf.fonttype': 42, \n",
    "                     'ytick.major.size': 3, 'xtick.major.size': 3, 'ytick.minor.size': 2, 'ytick.major.pad': 2, 'xtick.major.pad': 2, \n",
    "                     'lines.linewidth': 1,\n",
    "                     'axes.spines.right': False, 'axes.spines.top': False, 'axes.labelpad': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the overall figure, gridspec, and add subfigure labels\n",
    "fig = plt.figure(figsize=(4.48819,1.25+1.5*3)) # 3.34646\n",
    "fig_gridspec = matplotlib.gridspec.GridSpec(4, 2, figure=fig,\n",
    "    wspace=0.4, hspace=0.4, height_ratios=([1.25]+[1.5]*3), width_ratios=(1,0.75))\n",
    "subfigures = {\n",
    "    'A': fig.add_subfigure(fig_gridspec[0,:]),\n",
    "    'B': fig.add_subfigure(fig_gridspec[1,0]),\n",
    "    'C': fig.add_subfigure(fig_gridspec[2,0]),\n",
    "    'D': fig.add_subfigure(fig_gridspec[3,0]),\n",
    "    'E': fig.add_subfigure(fig_gridspec[1:,1]),\n",
    "}\n",
    "for label, subfig in subfigures.items():\n",
    "    subfig.add_artist(matplotlib.text.Text(x=0, y=1, text=f'{label}', fontsize=base.font_sizes['subpanel_label'], \n",
    "                                           fontweight='bold', verticalalignment='top',transform=subfig.transSubfigure))\n",
    "scatter_kwargs = dict(s=4, jitter=0.1, linewidth=0.5, edgecolor='white')\n",
    "xlim = (2e3,6e4)\n",
    "ylim = (1e1,5e3)\n",
    "\n",
    "fig_path = output_path/'fig_designs.pdf'\n",
    "fig.savefig(rd.outfile(fig_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def designs_stats_plots(axes, plot_df, plot_df2, marker_baseline=None, ylim=(0,1.2)):\n",
    "\n",
    "    xlim = (-0.5, len(plot_df['design'].unique())-0.5)\n",
    "\n",
    "    # stat gmean\n",
    "    ax = axes[0]\n",
    "    for construct, group in plot_df.groupby('construct'):\n",
    "        sns.stripplot(data=group, x='design', y='output_gmean', hue='construct', palette=designs_palette,\n",
    "                        legend=False, ax=ax, marker=designs_markers[construct], **scatter_kwargs)\n",
    "    ax.set(title='Output mean', xlim=xlim, xlabel='design', ylabel='', yscale='log',)\n",
    "    if marker_baseline: ax.axhline(marker_baseline, color='black', ls=':')\n",
    "    ax.minorticks_off()\n",
    "\n",
    "    # slope\n",
    "    ax = axes[1]\n",
    "    for construct, group in plot_df2.groupby('construct'):\n",
    "        sns.stripplot(data=group, x='design', y='slope', hue='construct', palette=designs_palette,\n",
    "                        legend=False, ax=ax, marker=designs_markers[construct], **scatter_kwargs)\n",
    "    ax.set(title='Slope', xlim=xlim, xlabel='', ylabel='', ylim=ylim,\n",
    "        yticks=[0,0.25,0.5,0.75,1], yticklabels=['0.0','','0.5','','1.0'])\n",
    "\n",
    "    for ax in axes: sns.despine(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfig = subfigures['B']\n",
    "rd.plot.adjust_subplot_margins_inches(subfig, left=0.7, bottom=0.35, top=0.35, right=0.15)\n",
    "axes = subfig.subplots(1,2, gridspec_kw=dict(width_ratios=(1,1), wspace=0.45))\n",
    "\n",
    "# transfection\n",
    "plot_df = stats[(((stats['miR']=='miRE.FF4') & (stats['group']=='controller') & (stats['ts_num']==1)) | (stats['group']=='base')) &\n",
    "                       (stats['promoter']=='EF1a')]\n",
    "plot_df2 = fits[(((fits['miR']=='miRE.FF4') & (fits['group']=='controller') & (fits['ts_num']==1)) | (fits['group']=='base')) &\n",
    "                       (fits['promoter']=='EF1a')]\n",
    "marker_baseline = stats.loc[(stats['group']=='marker'), 'output_gmean'].mean()\n",
    "\n",
    "designs_stats_plots(axes, plot_df, plot_df2, marker_baseline)\n",
    "\n",
    "fig.savefig(rd.outfile(fig_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfig = subfigures['C']\n",
    "rd.plot.adjust_subplot_margins_inches(subfig, left=0.7, bottom=0.35, top=0.35, right=0.15)\n",
    "axes = subfig.subplots(1,2, gridspec_kw=dict(width_ratios=(1,1), wspace=0.4))\n",
    "\n",
    "# PiggyBac integration\n",
    "plot_df = stats_pb\n",
    "plot_df2 = fits_pb\n",
    "designs_stats_plots(axes, plot_df, plot_df2)\n",
    "\n",
    "fig.savefig(rd.outfile(fig_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfig = subfigures['D']\n",
    "rd.plot.adjust_subplot_margins_inches(subfig, left=0.7, bottom=0.35, top=0.35, right=0.15)\n",
    "axes = subfig.subplots(1,2, gridspec_kw=dict(width_ratios=(1,1), wspace=0.4))\n",
    "\n",
    "# lenti (HEK293T)\n",
    "plot_df = stats_lenti[stats_lenti['group'].isin(['controller','base']) & (stats_lenti['dox']==1000) & (stats_lenti['virus_dilution']==1) & \n",
    "                      (stats_lenti['cell']=='293T') & ~((stats_lenti['biorep']<4) & (stats_lenti['design']==3))]\n",
    "plot_df2 = fits_lenti[fits_lenti['group'].isin(['controller','base']) & (fits_lenti['dox']==1000) & (fits_lenti['virus_dilution']==1) & \n",
    "                      (fits_lenti['cell']=='293T')&  ~((fits_lenti['biorep']<4) & (fits_lenti['design']==3))]\n",
    "marker_baseline = np.mean(data_lenti[(data_lenti['construct']=='UT') & (data_lenti['cell_type']=='293T')].groupby(['exp','biorep'])['output'].apply(sp.stats.gmean))\n",
    "\n",
    "designs_stats_plots(axes, plot_df, plot_df2, marker_baseline, ylim=(0,1))\n",
    "axes[0].minorticks_on()\n",
    "axes[0].xaxis.set_tick_params(which='minor', bottom=False)\n",
    "\n",
    "fig.savefig(rd.outfile(fig_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfig = subfigures['E']\n",
    "rd.plot.adjust_subplot_margins_inches(subfig, left=0.55, bottom=0.35, top=0.35, right=0.05)\n",
    "axes = subfig.subplots(3,2,  gridspec_kw=dict(width_ratios=(1,0.4), hspace=0.88))\n",
    "\n",
    "plot_df = df_quantiles_lenti[(df_quantiles_lenti['group'].isin(['controller','base'])) & (df_quantiles_lenti['dox']==1000) & \n",
    "                             (df_quantiles_lenti['virus_dilution']==1) & (df_quantiles_lenti['cell']=='293T') &\n",
    "                             (((df_quantiles_lenti['biorep']==1) & (df_quantiles_lenti['design'].isin([1,2]))) | \n",
    "                              ((df_quantiles_lenti['biorep']==5) & (df_quantiles_lenti['design'].isin([0,3]))))]\n",
    "designs_list = [[0,1], [2], [3]]\n",
    "marker_baseline = np.mean(data_lenti[(data_lenti['construct']=='UT') & (data_lenti['cell_type']=='293T')].groupby(['exp','biorep'])['output'].apply(sp.stats.gmean))\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    # line plot\n",
    "    ax = axes[i,0]\n",
    "    d = plot_df[plot_df['design'].isin(designs_list[i])].copy()\n",
    "    sns.lineplot(data=d, x='bin_marker_quantiles_median', y='output', hue='construct', palette=designs_palette, \n",
    "                legend=False, dashes=False, style='construct', markers=designs_markers, ax=ax, markersize=4, markeredgewidth=0.5,\n",
    "                estimator=sp.stats.gmean, errorbar=lambda x: (sp.stats.gmean(x) / sp.stats.gstd(x), sp.stats.gmean(x) * sp.stats.gstd(x)))\n",
    "    ax.set(xscale='log', yscale='log', xlabel='marker', ylim=ylim, xlim=xlim)\n",
    "    sns.despine(ax=ax)\n",
    "    ax.axhline(marker_baseline, color='black', ls=':')\n",
    "    ax.minorticks_on()\n",
    "    ax.yaxis.set_tick_params(which='minor', left=False)\n",
    "\n",
    "    # histogram\n",
    "    ax = axes[i,1]\n",
    "    sns.kdeplot(data=d, y='output', hue='construct', palette=designs_palette, \n",
    "                legend=False, log_scale=True, common_norm=False, ax=ax)\n",
    "    sns.despine(ax=ax, bottom=True)\n",
    "    ax.set(xlabel='', ylim=axes[i,0].get_ylim(), ylabel='', yticklabels=[])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.minorticks_off()\n",
    "\n",
    "axes[0,0].set_title('Design 1', color=base.colors['teal'])\n",
    "axes[1,0].set_title('Design 2', color=base.colors['orange'])\n",
    "axes[2,0].set_title('Design 3', color=base.colors['red'])\n",
    "\n",
    "fig.savefig(rd.outfile(fig_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
