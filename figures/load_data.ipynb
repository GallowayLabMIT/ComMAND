{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datasets:\n",
    "\n",
    "- tuning\n",
    "- miR characterization\n",
    "- model param sweeps\n",
    "- stochastic sims\n",
    "- two-gene \n",
    "- PiggyBac\n",
    "- lenti (293T, MEF)\n",
    "- lenti neuron\n",
    "- lenti T cell\n",
    "- lenti iPS11\n",
    "- iPS11 transfection\n",
    "- therapeutic transfection\n",
    "- therapeutic infection (TODO)\n",
    "- RT-qPCR (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "actions:\n",
    "\n",
    "- load data into dataframe\n",
    "- add metadata\n",
    "- gate cells\n",
    "- calculate statistics\n",
    "- define color palettes / marker dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rushd as rd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# enables concurrent editing of base.py\n",
    "from importlib import reload\n",
    "reload(base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "\n",
    "Inputs:\n",
    "- `base_path`: path to where all data is located\n",
    "- `metadata_path`: path to metadata spreadsheet\n",
    "- `data_group`: which groups of data to load and merge into a single dataframe\n",
    "\n",
    "Outputs:\n",
    "- `data`: dataframe with data, metadata, gating (column `gated`)\n",
    "- `df_quantiles`: dataframe with stats for each condition grouped by marker quantiles, plus metadata\n",
    "- `df_stats`: dataframe with stats for each condition, plus metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tuning\n",
    "- miR characterization\n",
    "- two-gene \n",
    "- PiggyBac\n",
    "- lenti (293T, MEF)\n",
    "- lenti neuron\n",
    "- lenti T cell\n",
    "- lenti iPS11\n",
    "- iPS11 transfection\n",
    "- therapeutic transfection\n",
    "- therapeutic infection (TODO)\n",
    "\n",
    "- model param sweeps\n",
    "- stochastic sims\n",
    "- RT-qPCR (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `load_plates` loads and gates data, renaming channels as needed\n",
    "def load_plates(data_group, base_path):\n",
    "    if data_group == 'tuning': return load_plates_tuning(base_path)\n",
    "    elif data_group == 'miR_characterization': return load_plates_miR_characterization(base_path)\n",
    "    elif data_group == 'two_gene': return load_plates_two_gene(base_path)\n",
    "    elif data_group == 'piggybac': return load_plates_piggybac(base_path)\n",
    "    elif data_group == 'lenti_293T_MEF': return load_plates_lenti_293T_mef(base_path)\n",
    "    elif data_group == 'lenti_tcell': return load_plates_lenti_tcell(base_path)\n",
    "    elif data_group == 'lenti_neuron': return load_plates_lenti_neuron(base_path)\n",
    "    elif data_group == 'lenti_iPS11': return load_plates_lenti_ips11(base_path)\n",
    "    elif data_group == 'iPS11_transfection': return load_plates_ips11_transfection(base_path)\n",
    "    elif data_group == 'therapeutic_transfection': return load_plates_therapeutic_transfection(base_path)\n",
    "    elif data_group == 'therapeutic_infection': return load_plates_lenti_therapeutic(base_path)\n",
    "    else: print(f'{data_group} is not a valid data group to load plates.')\n",
    "\n",
    "def load_plates_tuning(base_path):\n",
    "    exp90_path = base_path/'kasey'/'2024.03.31_exp90'/'export'\n",
    "    exp90_2_path = base_path/'kasey'/'2024.04.02_exp90.2'/'export'\n",
    "    exp90_3_path = base_path/'kasey'/'2024.04.02_exp90.3'/'export'\n",
    "    exp90_4_path = base_path/'kasey'/'2024.04.05_exp90.4'/'export'\n",
    "    exp91_path = base_path/'kasey'/'2024.04.08_exp91'/'export'\n",
    "    exp92_path = base_path/'kasey'/'2024.04.12_exp92'/'export'\n",
    "\n",
    "    plates = pd.DataFrame({\n",
    "        'data_path': [exp90_path/'plate1', exp90_path/'plate2', \n",
    "                    exp90_2_path, exp90_4_path,\n",
    "                    exp90_3_path/'plate1', exp90_3_path/'plate2', \n",
    "                    exp91_path/'plate1.1', exp91_path/'plate1.2', exp91_path/'plate1.3', \n",
    "                    exp91_path/'plate2.1', exp91_path/'plate2.2', exp91_path/'plate2.3',\n",
    "                    exp92_path/'plate1.1', exp92_path/'plate1.2', exp92_path/'plate1.3', \n",
    "                    exp92_path/'plate2.1', exp92_path/'plate2.2', exp92_path/'plate2.3',],\n",
    "        \n",
    "        'yaml_path': ([exp90_path/'exp90_plate1_wells.yaml', exp90_path/'exp90_plate2_wells.yaml', \n",
    "                    exp90_path/'exp90_plate2_wells.yaml', exp90_path/'exp90_plate1_wells.yaml',\n",
    "                    exp90_path/'exp90_plate1_wells.yaml', exp90_path/'exp90_plate2_wells.yaml', ] +\n",
    "                    [exp91_path/'exp91_plate1_wells.yaml']*3 + \n",
    "                    [exp91_path/'exp91_plate2.1_wells.yaml', exp91_path/'exp91_plate2.2_wells.yaml', exp91_path/'exp91_plate2.3_wells.yaml'] +\n",
    "                    [exp92_path/'exp92_plate1_wells.yaml', exp92_path/'exp92_plate1.2_wells.yaml', exp92_path/'exp92_plate1_wells.yaml',\n",
    "                    exp92_path/'exp92_plate2_wells.yaml', exp92_path/'exp92_plate2.2_wells.yaml', exp92_path/'exp92_plate2_wells.yaml',]\n",
    "                    ),\n",
    "        \n",
    "        'biorep': ([1, 1, \n",
    "                    2, 2, \n",
    "                    3, 3,] + \n",
    "                    [1, 2, 3,]*4),\n",
    "        \n",
    "        'exp': (['exp90', 'exp90', \n",
    "                'exp90.2', 'exp90.4', \n",
    "                'exp90.3', 'exp90.3',] + \n",
    "                ['exp91']*6 + \n",
    "                ['exp92']*6)\n",
    "    })\n",
    "    \n",
    "    # Load data\n",
    "    channel_list = ['mRuby2-A','mGL-A']\n",
    "    data = rd.flow.load_groups_with_metadata(plates, columns=channel_list)\n",
    "\n",
    "    # Remove negative channel values\n",
    "    for c in channel_list: data = data[data[c]>0]\n",
    "\n",
    "    # Draw gates\n",
    "    gates = pd.DataFrame()\n",
    "    for channel in channel_list:\n",
    "        gates[channel] = data[data['construct']=='UT'].groupby(['exp'])[channel].apply(lambda x: x.quantile(0.999))\n",
    "    gates.reset_index(inplace=True)\n",
    "\n",
    "    # Add missing gates\n",
    "    gates.loc[len(gates.index)] = ['exp90.4',0,0,]  \n",
    "    gates.loc[gates['exp']=='exp90.4', channel_list] = gates.loc[gates['exp']=='exp90.2', channel_list].values\n",
    "\n",
    "    # Indicate which channels are relevant for each experiment\n",
    "    gates.sort_values(['exp'], inplace=True)\n",
    "    gates['marker'] = 'mGL-A'\n",
    "    gates['output'] = 'mRuby2-A'\n",
    "\n",
    "    # Gate data by marker expression\n",
    "    data = data.groupby('exp')[data.columns].apply(lambda x: base.gate_data(x,gates))\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    data['gated'] = data['expressing'] & (data['construct']!='UT')\n",
    "    \n",
    "    return data\n",
    "    \n",
    "def load_plates_miR_characterization(base_path): \n",
    "    exp11_path = base_path/'Emma'/'2022.10.11_EXP11'/'Data'\n",
    "    exp11_controls_path = base_path/'Emma'/'2022.10.11_EXP10'/'data_controls'\n",
    "    exp49_path = base_path/'Emma'/'2024.04.06_EXP11_replicates'/'Plate_1_EXP49'/'data_singlets'\n",
    "    exp50_path = base_path/'Emma'/'2024.04.06_EXP11_replicates'/'Plate_2_EXP50'/'data_singlets'\n",
    "    exp49_50_controls_path = base_path/'Emma'/'2024.04.06_EXP11_replicates'/'Plate_3_Controls'/'data_singlets'\n",
    "\n",
    "    plates = pd.DataFrame({\n",
    "        'data_path': [base_path/'Emma'/'2022.10.04_EXP9'/'Data',\n",
    "                    base_path/'Emma'/'2023.01.16_EXP12'/'Data',\n",
    "                    base_path/'Emma'/'2023.02.09_EXP13'/'Data',\n",
    "                    exp11_path, exp11_controls_path, \n",
    "                    exp49_path, exp50_path, \n",
    "                    exp49_50_controls_path, exp49_50_controls_path],\n",
    "        \n",
    "        'yaml_path': ([base_path/'Emma'/'2022.10.04_EXP9'/'Data'/'wells_KL.yaml']*3 + \n",
    "                    [exp11_path/'wells_KL.yaml', exp11_controls_path/'wells_KL.yaml', \n",
    "                    exp11_path/'wells_KL.yaml', exp11_path/'wells_KL.yaml', \n",
    "                    exp49_50_controls_path/'wells_KL.yaml', exp49_50_controls_path/'wells2_KL.yaml', ]),\n",
    "        \n",
    "        'biorep': [1,2,3,\n",
    "                1,1,\n",
    "                2,3,\n",
    "                2,3],\n",
    "\n",
    "        'exp': ['ELP_exp09', 'ELP_exp12', 'ELP_exp13',\n",
    "                'ELP_exp11', 'ELP_exp11',\n",
    "                'ELP_exp49', 'ELP_exp50',\n",
    "                'ELP_exp49', 'ELP_exp50',],\n",
    "    })\n",
    "    \n",
    "    # Load data\n",
    "    channel_list = ['mRuby2-A','mGL-A']\n",
    "    data = rd.flow.load_groups_with_metadata(plates, columns=channel_list)\n",
    "    \n",
    "    # Remove negative channel values\n",
    "    for c in channel_list: data = data[data[c]>0]\n",
    "\n",
    "    # Draw gates\n",
    "    gates = pd.DataFrame()\n",
    "    for channel in channel_list:\n",
    "        gates[channel] = data[data['ts_construct']=='UT'].groupby(['exp'])[channel].apply(lambda x: x.quantile(0.999))\n",
    "    gates.reset_index(inplace=True)\n",
    "\n",
    "    # Indicate which channels are relevant for each experiment\n",
    "    gates.sort_values(['exp'], inplace=True)\n",
    "    gates['marker'] = 'mGL-A'\n",
    "    gates['output'] = 'mRuby2-A'\n",
    "\n",
    "    # Gate data by marker expression\n",
    "    data = data.groupby('exp')[data.columns].apply(lambda x: base.gate_data(x,gates))\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    data['gated'] = data['expressing'] & (data['ts_construct']!='UT')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_plates_two_gene(base_path):\n",
    "    plates = pd.DataFrame({\n",
    "        'data_path': [base_path/'kasey'/'2024.04.14_exp93'/'export'/f'plate{n}' for n in range(1,4)] + [base_path/'kasey'/'2024.10.21_exp093.2'/'export'],\n",
    "        'yaml_path': [base_path/'kasey'/'2024.04.14_exp93'/'export'/'exp93_wells.yaml']*3 + [base_path/'kasey'/'2024.10.21_exp093.2'/'export'/'wells.yaml'],\n",
    "        'biorep': [1, 2, 3, 4],\n",
    "        'exp': ['exp093']*3 + ['exp093.2'],\n",
    "    })\n",
    "\n",
    "    # Load data\n",
    "    channel_list = ['mRuby2-A','mGL-A','tagBFP-A','SNAP-647-A']\n",
    "    data = rd.flow.load_groups_with_metadata(plates, columns=channel_list)\n",
    "\n",
    "    # Remove negative channel values\n",
    "    for c in channel_list: data = data[data[c]>0]\n",
    "\n",
    "    # Rename far-red channel\n",
    "    data.rename(columns={'SNAP-647-A': 'iRFP670-A'}, inplace=True)\n",
    "    channel_list = ['mRuby2-A','mGL-A','tagBFP-A','iRFP670-A']\n",
    "    \n",
    "    # Draw gates\n",
    "    gates = pd.DataFrame()\n",
    "    for channel in channel_list:\n",
    "        gates[channel] = data[data['construct']=='GEEC555'].groupby(['exp'])[channel].apply(lambda x: x.quantile(0.999))\n",
    "    gates.reset_index(inplace=True)\n",
    "    display(gates)\n",
    "    # Add manual iRFP670 gate (forgot to include untransfected well)\n",
    "    gate_iRFP = 2.5e2\n",
    "    gates['iRFP670-A'] = [gate_iRFP]*len(data['exp'].unique())\n",
    "\n",
    "    # Indicate which channels are relevant for each experiment (same for both exp093 & exp093.2)\n",
    "    gates.sort_values(['exp'], inplace=True)\n",
    "    gates['marker'] = 'iRFP670-A'\n",
    "    gates['output'] = 'mRuby2-A'\n",
    "\n",
    "    # Gate data by marker expression\n",
    "    data = data.groupby('exp')[data.columns].apply(lambda x: base.gate_data(x,gates))\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    data['gated'] = data['expressing'] & (data['construct']!='UT')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_plates_piggybac(base_path):\n",
    "    pb_path = base_path/'kasey'/'2023.07.18_exp63.3-RC'/'export'\n",
    "\n",
    "    plates = pd.DataFrame({\n",
    "        'data_path': [pb_path],\n",
    "        'yaml_path': [pb_path/'exp63.3_wells2.yaml'],\n",
    "        'biorep': [1],\n",
    "        'exp': ['exp63.3-RC']\n",
    "    })\n",
    "    \n",
    "    # Load data\n",
    "    channel_list = ['mRuby2-A','mGL-A']\n",
    "    data = rd.flow.load_groups_with_metadata(plates, columns=channel_list)\n",
    "\n",
    "    # Remove negative channel values\n",
    "    for c in channel_list: data = data[data[c]>0]\n",
    "\n",
    "    # Manually draw gates\n",
    "    gates = pd.DataFrame({'exp': ['exp63.3-RC'], 'mGL-A': [200], 'mRuby2-A': [200]})\n",
    "\n",
    "    # Indicate which channels are relevant for each experiment\n",
    "    gates.sort_values(['exp'], inplace=True)\n",
    "    gates['marker'] = 'mGL-A'\n",
    "    gates['output'] = 'mRuby2-A'\n",
    "\n",
    "    # Gate data by marker expression\n",
    "    data = data.groupby('exp')[data.columns].apply(lambda x: base.gate_data(x,gates))\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    data['gated'] = data['expressing'] & (data['construct']!='UT')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_plates_lenti_293T_mef(base_path):\n",
    "    base_path_1 = base_path/'kasey'/'2024.04.05_exp89'/'export'\n",
    "    base_path_2 = base_path/'chris'/'2024.06.02-exp95-lenti-miR-iFFL'/'export'\n",
    "    plate_list = ['_'.join(x) for x in zip(\n",
    "            ['plate'+str(i) for i in range(1,10)], \n",
    "            (['293T']*3 + ['MEF2A']*3 + ['MEF8A']*3),\n",
    "            ['P9','P14','P15']*3\n",
    "        )]\n",
    "\n",
    "    plates = pd.DataFrame({\n",
    "        'data_path': [base_path_1/'293T_control', \n",
    "                    base_path_1/'293T_plate1', base_path_1/'293T_plate2', base_path_1/'293T_plate3',\n",
    "                    base_path_1/'MEF_3_plate1', \n",
    "                    base_path_1/'MEF_4-1_plate1', base_path_1/'MEF_4-1_plate2', base_path_1/'MEF_4-1_plate3'] +\n",
    "                    [base_path_2/p for p in plate_list],\n",
    "        'yaml_path': [base_path_1/'kasey_yaml2'/'plate_control.yaml', \n",
    "                    base_path_1/'kasey_yaml2'/'plate01.yaml', base_path_1/'kasey_yaml2'/'plate02.yaml', base_path_1/'kasey_yaml2'/'plate03.yaml',\n",
    "                    base_path_1/'kasey_yaml2'/'mef_3_plate01.yaml', \n",
    "                    base_path_1/'kasey_yaml2'/'mef_4-1_plate01.yaml', base_path_1/'kasey_yaml2'/'mef_4-1_plate02.yaml', base_path_1/'kasey_yaml2'/'mef_4-1_plate03.yaml'] +\n",
    "                    [base_path_2/(p+'_metadata.yaml') for p in plate_list],\n",
    "    })\n",
    "\n",
    "    # Load data\n",
    "    channel_list = ['mRuby2-A','mGL-A']\n",
    "    data = rd.flow.load_groups_with_metadata(plates, columns=channel_list)\n",
    "\n",
    "    # Remove negative channel values\n",
    "    for c in channel_list: data = data[data[c]>0]\n",
    "\n",
    "    # Add more metadata\n",
    "    data['exp'] = data['cell_type'] + '_' + data['virus_batch']\n",
    "    data['cell'] = data['cell_type'].apply(lambda x: x.split('-')[0])\n",
    "    data = data.groupby('cell')[data.columns].apply(base.map_biorep).reset_index(drop=True)\n",
    "    data['moi'] = data['virus_dilution']\n",
    "\n",
    "    # Draw gates\n",
    "    gates = pd.DataFrame()\n",
    "    for channel in channel_list:\n",
    "        gates[channel] = data[(data['virus_dilution']==0)].groupby(['exp'])[channel].apply(lambda x: x.quantile(0.999))\n",
    "    gates.reset_index(inplace=True)\n",
    "\n",
    "    # Define gates based on control plate\n",
    "    gates.loc[len(gates.index)] = ['293T_P10'] + list(gates.loc[gates['exp']=='293T_na', channel_list].mean().values)\n",
    "    gates.loc[len(gates.index)] = ['293T_P14_'] + list(gates.loc[gates['exp']=='293T_na', channel_list].mean().values)\n",
    "    gates.loc[len(gates.index)] = ['293T_P16'] + list(gates.loc[gates['exp']=='293T_na', channel_list].mean().values) \n",
    "    gates.loc[len(gates.index)] = ['MEF-3_P10'] + list(gates.loc[gates['exp'].str.contains('MEF'), channel_list].mean().values)\n",
    "    gates.loc[len(gates.index)] = ['MEF-4-1_P10'] + list(gates.loc[gates['exp'].str.contains('MEF'), channel_list].mean().values)\n",
    "    gates.loc[len(gates.index)] = ['MEF-4-1_P14'] + list(gates.loc[gates['exp'].str.contains('MEF'), channel_list].mean().values)\n",
    "    gates.loc[len(gates.index)] = ['MEF-4-1_P16'] + list(gates.loc[gates['exp'].str.contains('MEF'), channel_list].mean().values)\n",
    "\n",
    "    # Indicate which channels are relevant for each experiment\n",
    "    gates.sort_values(['exp'], inplace=True)\n",
    "    gates['marker'] = 'mGL-A'\n",
    "    gates['output'] = 'mRuby2-A'\n",
    "\n",
    "    # Gate data by marker expression\n",
    "    data = data.groupby('exp')[data.columns].apply(lambda x: base.gate_data(x,gates))\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    data['gated'] = data['expressing'] & (data['virus_dilution']!=0)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# ignore base_path for just this one right now, will change later\n",
    "def load_plates_lenti_tcell(base_path):\n",
    "    tcell_path = rd.datadir/'instruments'/'data'/'collaborators'/'birnbaum_steph'\n",
    "\n",
    "    plates = pd.DataFrame({\n",
    "        'data_path': [tcell_path/'2024-06-10 Galloway Exp 1'/'export', tcell_path/'2024-10-25 Galloway 2'/'export'],\n",
    "        'yaml_path': [tcell_path/'2024-06-10 Galloway Exp 1'/'metadata.yaml', tcell_path/'2024-10-25 Galloway 2'/'export'/'metadata.yaml'],\n",
    "        'biorep': [1, 2],\n",
    "        'exp': ['steph1', 'steph2']\n",
    "    })\n",
    "    \n",
    "    # Load data\n",
    "    channel_list = ['FITC-A', 'PE-A', 'APC-A750-A', 'PB450-A']\n",
    "    data = rd.flow.load_groups_with_metadata(plates, columns=channel_list)\n",
    "\n",
    "    # Rename channels\n",
    "    d1 = data[data['biorep']==1].copy()\n",
    "    d2 = data[data['biorep']==2].copy()\n",
    "    d1 = d1.rename({'FITC-A': 'mGL-A', 'PE-A': 'mRuby2-A', 'APC-A750-A': 'livedead-A'}, axis=1)\n",
    "    d2 = d2.rename({'FITC-A': 'mGL-A', 'PE-A': 'mRuby2-A', 'PB450-A': 'livedead-A'}, axis=1)\n",
    "    data = pd.concat([d1, d2], ignore_index=True)\n",
    "\n",
    "    # Remove negative channel values\n",
    "    channel_list = ['mGL-A', 'mRuby2-A', 'livedead-A']\n",
    "    for c in channel_list: data = data[data[c]>0]\n",
    "\n",
    "    # Draw gates\n",
    "    gates = pd.DataFrame()\n",
    "    for channel in channel_list:\n",
    "        gates[channel] = data[data['construct']=='UT'].groupby(['exp'])[channel].apply(lambda x: x.quantile(0.9999))\n",
    "    gates.reset_index(inplace=True)\n",
    "\n",
    "    # Indicate which channels are relevant for each experiment\n",
    "    gates.sort_values(['exp'], inplace=True)\n",
    "    gates['marker'] = 'mGL-A'\n",
    "    gates['output'] = 'mRuby2-A'\n",
    "\n",
    "    # Gate data by marker expression\n",
    "    data = data.groupby('exp')[data.columns].apply(lambda x: base.gate_data(x,gates))\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Gate live cells (livedead-A < manual gate)\n",
    "    data.loc[data['biorep']==1, 'live'] = data.loc[data['biorep']==1, 'livedead-A'] < 2e3\n",
    "    data.loc[data['biorep']==2, 'live'] = data.loc[data['biorep']==2, 'livedead-A'] < 7e4\n",
    "\n",
    "    data['gated'] = data['expressing'] & data['live'] & (data['construct']!='UT')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_plates_lenti_neuron(base_path):\n",
    "    neuron_path = base_path/'chris'/'2024.06.15-rat-neurons'\n",
    "\n",
    "    plates = pd.DataFrame({\n",
    "        'data_path': [neuron_path/'export'],\n",
    "        'yaml_path': [neuron_path/'metadata.yaml'],\n",
    "        'biorep': [1],\n",
    "        'exp': ['exp098'],\n",
    "        'cell': ['neuron'],\n",
    "        'dox': [1000]\n",
    "    })\n",
    "    \n",
    "    # Load data\n",
    "    channel_list = ['mRuby2-A','mGL-A']\n",
    "    data = rd.flow.load_groups_with_metadata(plates, columns=channel_list)\n",
    "\n",
    "    # Remove negative channel values\n",
    "    for c in channel_list: data = data[data[c]>0]\n",
    "\n",
    "    # Draw gates\n",
    "    gates = pd.DataFrame()\n",
    "    for channel in channel_list:\n",
    "        gates[channel] = data[data['construct']=='UT'].groupby(['exp'])[channel].apply(lambda x: x.quantile(0.999))\n",
    "    gates.reset_index(inplace=True)\n",
    "\n",
    "    # Adjust marker gate to better isolate infected population\n",
    "    gates['mGL-A'] = 1e3\n",
    "\n",
    "    # Indicate which channels are relevant for each experiment\n",
    "    gates.sort_values(['exp'], inplace=True)\n",
    "    gates['marker'] = 'mGL-A'\n",
    "    gates['output'] = 'mRuby2-A'\n",
    "\n",
    "    # Gate data by marker expression\n",
    "    data = data.groupby('exp')[data.columns].apply(lambda x: base.gate_data(x,gates))\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    data['gated'] = data['expressing'] & (data['construct']!='UT')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_plates_lenti_ips11(base_path):\n",
    "    plates = pd.DataFrame({\n",
    "        'data_path': [base_path/'kasey'/'2024.10.03_exp116'/'export'/'plate2', base_path/'kasey'/'2024.10.21_exp116.2'/'export'],\n",
    "        'yaml_path': [base_path/'kasey'/'2024.10.03_exp116'/'export'/'plate2'/'exp116_wells.yaml', base_path/'kasey'/'2024.10.21_exp116.2'/'export'/'wells.yaml'],\n",
    "    })\n",
    "\n",
    "    # Load data\n",
    "    channel_list = ['mRuby2-A','mGL-A']\n",
    "    data = rd.flow.load_groups_with_metadata(plates, columns=channel_list)\n",
    "    data = data[~data['construct'].isna()]\n",
    "\n",
    "    # Add more metadata\n",
    "    data['exp'] = 'exp116_' + data['biorep'].astype(str)\n",
    "\n",
    "    # Remove negative channel values\n",
    "    for c in channel_list: data = data[data[c]>0]\n",
    "\n",
    "    # Draw gates\n",
    "    gates = pd.DataFrame()\n",
    "    for channel in channel_list:\n",
    "        gates[channel] = data[data['construct']=='UI'].groupby(['exp'])[channel].apply(lambda x: x.quantile(0.999))\n",
    "    gates.reset_index(inplace=True)\n",
    "\n",
    "    # Adjust marker gate to better isolate infected population\n",
    "    gates['mGL-A'] = [2e3]*3\n",
    "\n",
    "    # Indicate which channels are relevant for each experiment\n",
    "    gates.sort_values(['exp'], inplace=True)\n",
    "    gates['marker'] = 'mGL-A'\n",
    "    gates['output'] = 'mRuby2-A'\n",
    "\n",
    "    # Gate data by marker expression\n",
    "    data = data.groupby('exp')[data.columns].apply(lambda x: base.gate_data(x,gates))\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    data['gated'] = data['expressing'] & (data['construct']!='UI')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_plates_ips11_transfection(base_path):\n",
    "    exp83_5_path = base_path/'kasey'/'2024.04.29_exp83.5'/'export'\n",
    "    plates = pd.DataFrame({\n",
    "        'data_path': [exp83_5_path, \n",
    "                      base_path/'Emma'/'2024.06.14_EXP65'/'data_singlets', base_path/'Emma'/'2024.06.21_EXP65.2'/'data_singlets'],\n",
    "        'yaml_path': [exp83_5_path/'exp83.5_wells.yaml']*3,\n",
    "        'biorep': [1, 2, 3],\n",
    "        'exp': ['exp83.5', 'elp_exp65', 'elp_exp65.2']\n",
    "    })\n",
    "\n",
    "    # Load data\n",
    "    channel_list = ['mRuby2-A','mGL-A']\n",
    "    data = rd.flow.load_groups_with_metadata(plates, columns=channel_list)\n",
    "    \n",
    "    # Remove negative channel values\n",
    "    for c in channel_list: data = data[data[c]>0]\n",
    "\n",
    "    # Rename channels\n",
    "    d1 = data[data['exp']=='exp83.5'].copy()\n",
    "    d2 = data[data['exp']!='exp83.5'].copy()\n",
    "    d2 = d2.rename(columns={'YL1-A': 'mRuby2-A', 'mRuby2-A': 'mCherry-A'}, inplace=True)\n",
    "    data = pd.concat([d1, d2], ignore_index=True)\n",
    "    \n",
    "    # Draw gates\n",
    "    gates = pd.DataFrame()\n",
    "    for channel in channel_list:\n",
    "        gates[channel] = data[data['construct']=='UT'].groupby(['exp'])[channel].apply(lambda x: x.quantile(0.999))\n",
    "    gates.reset_index(inplace=True)\n",
    "\n",
    "    # Indicate which channels are relevant for each experiment\n",
    "    gates.sort_values(['exp'], inplace=True)\n",
    "    gates['marker'] = 'mGL-A'\n",
    "    gates['output'] = 'mRuby2-A'\n",
    "    \n",
    "    # Gate data by marker expression\n",
    "    data = data.groupby('exp')[data.columns].apply(lambda x: base.gate_data(x,gates))\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    data['gated'] = data['expressing'] & (data['construct']!='UT')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_plates_therapeutic_transfection(base_path):\n",
    "    rep1_2_path = base_path/'Emma'/'2024.06.05_EXP56'/'data_singlets'\n",
    "    rep3_path = base_path/'Emma'/'2024.06.09_EXP60'/'data_singlets'\n",
    "\n",
    "    plates = pd.DataFrame({\n",
    "        'data_path': [rep1_2_path, rep1_2_path, rep3_path],\n",
    "        'yaml_path': [rep1_2_path/'elp_exp56_biorep_1_wells.yaml', rep1_2_path/'elp_exp56_biorep_2_wells.yaml', rep3_path/'elp_exp56_biorep_3_wells.yaml'],\n",
    "        'exp': ['elp_exp56.1','elp_exp56.2','elp_exp60'],\n",
    "        'biorep': [1,2,3]\n",
    "    })\n",
    "\n",
    "    # Load data\n",
    "    channel_list = ['mRuby2-A','EGFP-A','iRFP-A']\n",
    "    data = rd.flow.load_groups_with_metadata(plates, columns=channel_list)\n",
    "\n",
    "    # Remove negative channel values\n",
    "    for c in channel_list: data = data[data[c]>0]\n",
    "\n",
    "    # Draw gates\n",
    "    gates = pd.DataFrame()\n",
    "    for channel in channel_list:\n",
    "        gates[channel] = data[data['construct']=='UT'].groupby(['exp'])[channel].apply(lambda x: x.quantile(0.999))\n",
    "    gates.reset_index(inplace=True)\n",
    "\n",
    "    # Indicate which channels are relevant for each experiment\n",
    "    gates.sort_values(['exp'], inplace=True)\n",
    "    gates['marker'] = 'iRFP-A'\n",
    "    gates['output'] = 'mRuby2-A' # only for FXN\n",
    "\n",
    "    # Gate data by marker expression\n",
    "    data = data.groupby('exp')[data.columns].apply(lambda x: base.gate_data(x,gates))\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    data['gated'] = data['expressing'] & (data['construct']!='UT')\n",
    "    \n",
    "    return data\n",
    "\n",
    "# TODO once data collected\n",
    "def load_plates_lenti_therapeutic(base_path):\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tuning: construct\n",
    "- miR characterization: miR_construct, ts_construct\n",
    "- two gene: construct, construct2\n",
    "- lenti: cell, moi, dox, construct\n",
    "- application transfection: construct, data_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(base_path, metadata_path, which):\n",
    "    if which == 'tuning': return load_data_tuning(base_path, metadata_path)\n",
    "    elif which == 'miR_characterization': return load_data_miR_characterization(base_path, metadata_path)\n",
    "    elif which == 'two_gene': return load_data_two_gene(base_path, metadata_path)\n",
    "    elif which == 'piggybac': return load_data_piggybac(base_path, metadata_path)\n",
    "    elif which == 'lenti': return load_data_lenti(base_path, metadata_path) # all lentivirus data (all cell types)\n",
    "    elif which == 'application': return load_data_application(base_path, metadata_path) # iPS11 and therapeutic gene transfections\n",
    "    else: print(f'{which} is not a valid data group.')\n",
    "\n",
    "def load_data_tuning(base_path, metadata_path):\n",
    "\n",
    "    # Load and gate raw data\n",
    "    cache_path = rd.rootdir/'data'/('tuning.gzip')\n",
    "    data = pd.DataFrame()\n",
    "    if cache_path.is_file(): data = pd.read_parquet(cache_path)\n",
    "    else: \n",
    "        data = load_plates('tuning', base_path)\n",
    "        data.to_parquet(rd.outfile(cache_path))\n",
    "\n",
    "    # Bin data and calculate statistics\n",
    "    df_quantiles, df_stats = base.calculate_bins_stats(data[data['gated']])\n",
    "\n",
    "    # Add metadata\n",
    "    metadata = base.get_metadata(metadata_path/'construct-metadata.xlsx')\n",
    "    data = data.merge(metadata, how='left', on='construct')\n",
    "    df_quantiles = df_quantiles.merge(metadata, how='left', on='construct')\n",
    "    df_stats = df_stats.merge(metadata, how='left', on='construct')\n",
    "\n",
    "    return data, df_quantiles, df_stats, metadata\n",
    "\n",
    "def load_data_miR_characterization(base_path, metadata_path):\n",
    "\n",
    "    # Load and gate raw data\n",
    "    cache_path = rd.rootdir/'data'/('miR_characterization.gzip')\n",
    "    data = pd.DataFrame()\n",
    "    if cache_path.is_file(): data = pd.read_parquet(cache_path)\n",
    "    else: \n",
    "        data = load_plates('miR_characterization', base_path)\n",
    "        data.to_parquet(rd.outfile(cache_path))\n",
    "    \n",
    "    data['condition'] = data['miR_construct'] + '_' + data['ts_construct']\n",
    "\n",
    "    # Bin data and calculate statistics\n",
    "    df_quantiles, df_stats = base.calculate_bins_stats(data[data['gated']], by=['condition','miR_construct','ts_construct','biorep','exp'])\n",
    "\n",
    "    # Add metadata for miR_construct\n",
    "    metadata1 = pd.read_excel(metadata_path/'miR-metadata.xlsx')\n",
    "    data = data.merge(metadata1, how='left', on='miR_construct')\n",
    "    df_quantiles = df_quantiles.merge(metadata1, how='left', on='miR_construct')\n",
    "    df_stats = df_stats.merge(metadata1, how='left', on='miR_construct')\n",
    "\n",
    "    # Add metadata for ts_construct\n",
    "    metadata2 = pd.read_excel(metadata_path/'ts-metadata.xlsx')\n",
    "    data = data.merge(metadata2, how='left', on='ts_construct')\n",
    "    df_quantiles = df_quantiles.merge(metadata2, how='left', on='ts_construct')\n",
    "    df_stats = df_stats.merge(metadata2, how='left', on='ts_construct')\n",
    "\n",
    "    # Combine metadata\n",
    "    metadata = data.drop_duplicates('condition')[['miR_construct','ts_construct','condition']]\n",
    "    metadata = metadata.merge(metadata1, how='left', on='miR_construct')\n",
    "    metadata = metadata.merge(metadata2, how='left', on='ts_construct')\n",
    "\n",
    "    # For this experiment, compute fold-change expression of each ts relative to ts=none for each miR\n",
    "    df_stats = df_stats.groupby(by=['miR_construct','biorep','exp'])[df_stats.columns].apply(base.get_fc).reset_index(drop=True)\n",
    "\n",
    "    return data, df_quantiles, df_stats, metadata\n",
    "\n",
    "def load_data_two_gene(base_path, metadata_path):\n",
    "\n",
    "    # Load and gate raw data\n",
    "    cache_path = rd.rootdir/'data'/('two_gene.gzip')\n",
    "    data = pd.DataFrame()\n",
    "    if cache_path.is_file(): data = pd.read_parquet(cache_path)\n",
    "    else: \n",
    "        data = load_plates('two_gene', base_path)\n",
    "        data.to_parquet(rd.outfile(cache_path))\n",
    "\n",
    "    data['condition'] = data['construct'] + '_' + data['construct2']\n",
    "\n",
    "    # Bin data and calculate statistics\n",
    "    df_quantiles, df_stats = base.calculate_bins_stats(data[data['gated']], by=['condition','construct','construct2','biorep','exp'])\n",
    "\n",
    "    # Add metadata for construct\n",
    "    metadata1 = base.get_metadata(metadata_path/'construct-metadata.xlsx')\n",
    "    data = data.merge(metadata1, how='left', on='construct')\n",
    "    df_quantiles = df_quantiles.merge(metadata1, how='left', on='construct')\n",
    "    df_stats = df_stats.merge(metadata1, how='left', on='construct')\n",
    "\n",
    "    # Add metadata for construct2\n",
    "    metadata2 = pd.read_excel(metadata_path/'construct2-metadata.xlsx')\n",
    "    data = data.merge(metadata2, how='left', on='construct2')\n",
    "    df_quantiles = df_quantiles.merge(metadata2, how='left', on='construct2')\n",
    "    df_stats = df_stats.merge(metadata2, how='left', on='construct2')\n",
    "\n",
    "    # Combine metadata\n",
    "    metadata = data.drop_duplicates('condition')[['construct','construct2','condition']]\n",
    "    metadata = metadata.merge(metadata1, how='left', on='construct')\n",
    "    metadata = metadata.merge(metadata2, how='left', on='construct2')\n",
    "\n",
    "    return data, df_quantiles, df_stats, metadata\n",
    "\n",
    "def load_data_piggybac(base_path, metadata_path):\n",
    "\n",
    "    # Load and gate raw data\n",
    "    cache_path = rd.rootdir/'data'/('piggybac.gzip')\n",
    "    data = pd.DataFrame()\n",
    "    if cache_path.is_file(): data = pd.read_parquet(cache_path)\n",
    "    else: \n",
    "        data = load_plates('piggybac', base_path)\n",
    "        data.to_parquet(rd.outfile(cache_path))\n",
    "\n",
    "    # Bin data and calculate statistics\n",
    "    df_quantiles, df_stats = base.calculate_bins_stats(data[data['gated']])\n",
    "\n",
    "    # Add metadata\n",
    "    metadata = base.get_metadata(metadata_path/'construct-metadata.xlsx')\n",
    "    data = data.merge(metadata, how='left', on='construct')\n",
    "    df_quantiles = df_quantiles.merge(metadata, how='left', on='construct')\n",
    "    df_stats = df_stats.merge(metadata, how='left', on='construct')\n",
    "\n",
    "    return data, df_quantiles, df_stats, metadata\n",
    "\n",
    "# Combine data from all lenti experiments\n",
    "def load_data_lenti(base_path, metadata_path):\n",
    "\n",
    "    data_groups = ['lenti_293T_MEF', 'lenti_tcell', 'lenti_neuron', 'lenti_iPS11']\n",
    "\n",
    "    data_list = []\n",
    "    for data_group in data_groups:\n",
    "        cache_path = rd.rootdir/'data'/(data_group+'.gzip')\n",
    "        data = pd.DataFrame()\n",
    "        if cache_path.is_file(): data = pd.read_parquet(cache_path)\n",
    "        else: \n",
    "            data = load_plates(data_group, base_path)\n",
    "            data.to_parquet(rd.outfile(cache_path))\n",
    "        data_list.append(data)\n",
    "    \n",
    "    # Combine data into a single dataframe\n",
    "    data = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "    # Bin data and calculate statistics\n",
    "    df_quantiles, df_stats = base.calculate_bins_stats(data[data['gated']], by=['construct','moi','dox','cell','biorep','exp'])\n",
    "\n",
    "    # Add metadata\n",
    "    metadata = base.get_metadata(metadata_path/'construct-metadata.xlsx')\n",
    "    data = data.merge(metadata, how='left', on='construct')\n",
    "    df_quantiles = df_quantiles.merge(metadata, how='left', on='construct')\n",
    "    df_stats = df_stats.merge(metadata, how='left', on='construct')\n",
    "\n",
    "    return data, df_quantiles, df_stats, metadata\n",
    "\n",
    "# Combine data from application-relevant transfections\n",
    "def load_data_application(base_path, metadata_path):\n",
    "\n",
    "    data_groups = ['therapeutic_transfection', 'iPS11_transfection']\n",
    "\n",
    "    data_list = []\n",
    "    for data_group in data_groups:\n",
    "        cache_path = rd.rootdir/'data'/(data_group+'.gzip')\n",
    "        data = pd.DataFrame()\n",
    "        if cache_path.is_file(): data = pd.read_parquet(cache_path)\n",
    "        else: \n",
    "            data = load_plates(data_group, base_path)\n",
    "            data['data_group'] = data_group\n",
    "            data.to_parquet(rd.outfile(cache_path))\n",
    "        data_list.append(data)\n",
    "    \n",
    "    # Combine data into a single dataframe\n",
    "    data = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "    # Add metadata\n",
    "    metadata = base.get_metadata(metadata_path/'construct-metadata.xlsx')\n",
    "    data = data.merge(metadata, how='left', on='construct')\n",
    "    data = data[~data['construct'].isna()]\n",
    "    \n",
    "    # Rename output channel for FMRP\n",
    "    data.loc[data['name'].str.contains('FMRP'), 'output'] = data.loc[data['name'].str.contains('FMRP'), 'EGFP-A']\n",
    "\n",
    "    # Bin data and calculate statistics\n",
    "    df_quantiles, df_stats = base.calculate_bins_stats(data[data['gated']], by=['data_group','construct','biorep','exp'])\n",
    "    df_quantiles = df_quantiles.merge(metadata, how='left', on='construct')\n",
    "    df_stats = df_stats.merge(metadata, how='left', on='construct')\n",
    "\n",
    "    return data, df_quantiles, df_stats, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load modeling\n",
    "\n",
    "Inputs:\n",
    "- `base_path`: path to where all data is located\n",
    "- `which`: which modeling results to load (parameter sweeps or stochastic simulations)\n",
    "\n",
    "Outputs:\n",
    "- `data`: dataframe with data (modeling results), metadata\n",
    "- `df_stats` or `slopes`: dataframe with additional stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modeling results\n",
    "def load_modeling(base_path, which):\n",
    "    if which == 'param_sweeps': return load_modeling_param_sweeps(base_path)\n",
    "    elif which == 'stochastic_sims': return load_modeling_stochastic_sims(base_path)\n",
    "    else: print(f'{which} is not a valid modeling type.')\n",
    "\n",
    "# later: move modeling results to different location\n",
    "#   current base_path = rd.rootdir/'output'\n",
    "def load_modeling_param_sweeps(base_path):\n",
    "\n",
    "    # Load parameter sweeps from ODE model\n",
    "    simulation_path = base_path/'modeling'/'julia_param_sweeps'/'per_param'/'sweep_df.gzip'\n",
    "    data = pd.DataFrame()\n",
    "    if simulation_path.is_file(): \n",
    "        data = pd.read_parquet(simulation_path)\n",
    "\n",
    "    # Normalize parameter values such that original (middle) value = 1\n",
    "    data = data.groupby('param')[data.columns].apply(base.normalize_param_val).reset_index(drop=True)\n",
    "\n",
    "    # Compute value of unregulated gene\n",
    "    alpha_rna = 4.67e-2     # params from `miR_iFFL.jl`\n",
    "    delta_mrna = 2.88e-4\n",
    "    alpha_p = 3.33e-4\n",
    "    delta_p = 9.67e-5\n",
    "    data['unreg'] = data['copy_num'] * (alpha_rna * alpha_p) / (delta_mrna * delta_p)\n",
    "\n",
    "    # Compute instantaneous slope for each param & param_val \n",
    "    col_list = ['copy_num','protein']\n",
    "    slopes = data.groupby(['param','param_val','param_val_norm'])[data.columns].apply(lambda x: base.get_slope_instant(x, *col_list)).rename('slope').reset_index()\n",
    "    slopes['base_norm_factor'] = (delta_mrna * delta_p) / (alpha_rna * alpha_p)\n",
    "\n",
    "    result = slopes.groupby(['param','param_val_norm'])[slopes.columns].apply(base.modify_norm_factor).rename('norm_factor').reset_index()\n",
    "    slopes['norm_factor'] = result['norm_factor']\n",
    "    slopes['slope_norm'] = slopes['slope'] * slopes['norm_factor']\n",
    "\n",
    "    return data, slopes\n",
    "\n",
    "# later: move modeling results to a different location\n",
    "#    current base_path = rd.datadir/'projects'/'miR-iFFL'\n",
    "def load_modeling_stochastic_sims(base_path):\n",
    "\n",
    "    # Load stochastic simulations\n",
    "    simulation_path = base_path/'modeling'/'julia_stochastic_simulations'/'stochastic_sims.gzip'\n",
    "    data = pd.DataFrame()\n",
    "    if simulation_path.is_file(): \n",
    "        data = pd.read_parquet(simulation_path)\n",
    "\n",
    "    # Rename columns/labels to match those for experimental data\n",
    "    data.rename(columns={'copynum': 'copy_num', 'reg_gene': 'output', 'unreg_gene': 'marker'}, inplace=True)\n",
    "    data['gene'] = data['design'].map({'Design 1': '1T', 'Design 2': '1T', 'Design 3': '1T',\n",
    "                                            'Dual Vector': '2V', 'Dual Transcript': '2T'})\n",
    "    data['design'] = data['design'].map({'Design 1': 1, 'Design 2': 2, 'Design 3': 3,\n",
    "                                            'Dual Vector': 0, 'Dual Transcript': 0})\n",
    "    data['kind'] = data['gene'] + '_' + data['design'].astype(str)\n",
    "    \n",
    "    # Bin data and calculate statistics\n",
    "    _, df_stats = base.calculate_bins_stats(data, by=['design','moi','risc','gene','kind'])\n",
    "\n",
    "    return data, df_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to raw data\n",
    "raw_path = Path('/Users/kaseylove/Desktop/code/ComMAND/raw') \n",
    "base_path = rd.datadir/'instruments'/'data'/'attune'\n",
    "data, quantiles, stats, metadata = load_data(base_path, rd.datadir/'projects'/'miR-iFFL'/'plasmids', 'lenti')\n",
    "display(data)\n",
    "display(stats)\n",
    "display(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
