{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rushd as rd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "\n",
    "# enables concurrent editing of base.py\n",
    "from importlib import reload\n",
    "reload(base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Circuit tuning data (`data`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = rd.datadir/'instruments'/'data'/'attune'/'kasey'\n",
    "\n",
    "exp90_path = base_path/'2024.03.31_exp90'/'export'\n",
    "exp90_2_path = base_path/'2024.04.02_exp90.2'/'export'\n",
    "exp90_3_path = base_path/'2024.04.02_exp90.3'/'export'\n",
    "exp90_4_path = base_path/'2024.04.05_exp90.4'/'export'\n",
    "exp91_path = base_path/'2024.04.08_exp91'/'export'\n",
    "exp92_path = base_path/'2024.04.12_exp92'/'export'\n",
    "\n",
    "plates = pd.DataFrame({\n",
    "    'data_path': [exp90_path/'plate1', exp90_path/'plate2', \n",
    "                  exp90_2_path, exp90_4_path,\n",
    "                  exp90_3_path/'plate1', exp90_3_path/'plate2', \n",
    "                  exp91_path/'plate1.1', exp91_path/'plate1.2', exp91_path/'plate1.3', \n",
    "                  exp91_path/'plate2.1', exp91_path/'plate2.2', exp91_path/'plate2.3',\n",
    "                  exp92_path/'plate1.1', exp92_path/'plate1.2', exp92_path/'plate1.3', \n",
    "                  exp92_path/'plate2.1', exp92_path/'plate2.2', exp92_path/'plate2.3',],\n",
    "    \n",
    "    'yaml_path': ([exp90_path/'exp90_plate1_wells.yaml', exp90_path/'exp90_plate2_wells.yaml', \n",
    "                   exp90_path/'exp90_plate2_wells.yaml', exp90_path/'exp90_plate1_wells.yaml',\n",
    "                   exp90_path/'exp90_plate1_wells.yaml', exp90_path/'exp90_plate2_wells.yaml', ] +\n",
    "                  [exp91_path/'exp91_plate1_wells.yaml']*3 + \n",
    "                  [exp91_path/'exp91_plate2.1_wells.yaml', exp91_path/'exp91_plate2.2_wells.yaml', exp91_path/'exp91_plate2.3_wells.yaml'] +\n",
    "                  [exp92_path/'exp92_plate1_wells.yaml', exp92_path/'exp92_plate1.2_wells.yaml', exp92_path/'exp92_plate1_wells.yaml',\n",
    "                   exp92_path/'exp92_plate2_wells.yaml', exp92_path/'exp92_plate2.2_wells.yaml', exp92_path/'exp92_plate2_wells.yaml',]\n",
    "                  ),\n",
    "    \n",
    "    'biorep': ([1, 1, \n",
    "                2, 2, \n",
    "                3, 3,] + \n",
    "                [1, 2, 3,]*4),\n",
    "    \n",
    "    'exp': (['exp90', 'exp90', \n",
    "             'exp90.2', 'exp90.4', \n",
    "             'exp90.3', 'exp90.3',] + \n",
    "            ['exp91']*6 + \n",
    "            ['exp92']*6)\n",
    "})\n",
    "\n",
    "output_path = rd.rootdir/'output'/'fig_designs-supp'\n",
    "cache_path = rd.rootdir/'output'/'fig_overview'/'data.gzip'\n",
    "metadata_path = rd.datadir/'projects'/'miR-iFFL'/'plasmids'/'construct-metadata.xlsx'\n",
    "\n",
    "# Load data\n",
    "data = pd.DataFrame()\n",
    "if cache_path.is_file(): data = pd.read_parquet(cache_path)\n",
    "else: \n",
    "    channel_list = ['mCherry-A','mRuby2-A','FSC-A','SSC-A','tagBFP-A','mGL-A']\n",
    "    data = rd.flow.load_groups_with_metadata(plates, columns=channel_list)\n",
    "\n",
    "    # Remove negative channel values\n",
    "    for c in channel_list: data = data[data[c]>0]\n",
    "    \n",
    "    data.dropna(inplace=True)\n",
    "    data.to_parquet(rd.outfile(cache_path))\n",
    "\n",
    "# Add metadata for constructs\n",
    "metadata = base.get_metadata(metadata_path, style='designs')\n",
    "data = data.merge(metadata, how='left', on='construct')\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dicts to specify colors/markers\n",
    "metadata_dict = metadata.set_index('construct').to_dict('dict')\n",
    "designs_palette = metadata_dict['color']\n",
    "designs_markers = metadata_dict['markers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gate cells\n",
    "gates = pd.DataFrame()\n",
    "channel_list = ['mGL-A', 'mRuby2-A']\n",
    "for channel in channel_list:\n",
    "    gates[channel] = data[data['construct']=='UT'].groupby(['exp'])[channel].apply(lambda x: x.quantile(0.999))\n",
    "gates.reset_index(inplace=True)\n",
    "\n",
    "# Add missing gates\n",
    "gates.loc[len(gates.index)] = ['exp90.4',0,0,]  \n",
    "gates.loc[gates['exp']=='exp90.4', channel_list] = gates.loc[gates['exp']=='exp90.2', channel_list].values\n",
    "\n",
    "# Indicate which channels are relevant for each experiment\n",
    "gates.sort_values(['exp'], inplace=True)\n",
    "gates['marker'] = 'mGL-A'\n",
    "gates['output'] = 'mRuby2-A'\n",
    "\n",
    "# Gate data by transfection marker expression\n",
    "data = data.groupby('exp')[data.columns].apply(lambda x: base.gate_data(x,gates))\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "df = data[(data['expressing']) & (data['construct']!='UT') & (data['exp']!='elp_exp61')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin data and calculate statistics\n",
    "df_quantiles, stats, _, fits = base.calculate_bins_stats(df, num_bins=20)\n",
    "stats = stats.merge(metadata, how='left', on='construct')\n",
    "fits = fits.merge(metadata, how='left', on='construct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_label = {'na': 'base', 'NT': 'OL', 'T': 'CL', 'none': 'â€“'}\n",
    "metadata['ts_label'] = metadata['ts_kind'].replace(ts_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two-gene data (`data2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = rd.datadir/'instruments'/'data'/'attune'/'kasey'\n",
    "exp93_path = base_path/'2024.04.14_exp93'/'export'\n",
    "\n",
    "plates = pd.DataFrame({\n",
    "    'data_path': [exp93_path/'plate1', exp93_path/'plate2', exp93_path/'plate3',],\n",
    "    'yaml_path': [exp93_path/'exp93_wells.yaml']*3,\n",
    "    'biorep': [1, 2, 3],\n",
    "    'exp': ['exp93']*3,\n",
    "})\n",
    "\n",
    "cache_path = rd.rootdir/'output'/'fig_architecture'/'data.gzip'\n",
    "\n",
    "# Load data\n",
    "data2 = pd.DataFrame()\n",
    "if cache_path.is_file(): data2 = pd.read_parquet(cache_path)\n",
    "else: \n",
    "    channel_list = ['mRuby2-A','FSC-A','SSC-A','tagBFP-A','mGL-A','SNAP-647-A']\n",
    "    data2 = rd.flow.load_groups_with_metadata(plates, columns=channel_list)\n",
    "\n",
    "    # Remove negative channel values\n",
    "    for c in channel_list: data2 = data2[data2[c]>0]\n",
    "    \n",
    "    data2.dropna(inplace=True)\n",
    "    data2.to_parquet(rd.outfile(cache_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metadata for constructs\n",
    "data2 = data2.merge(metadata, how='left', on='construct')\n",
    "metadata_construct2 = pd.read_excel(rd.datadir/'projects'/'miR-iFFL'/'plasmids'/'construct2-metadata.xlsx')\n",
    "data2 = data2.merge(metadata_construct2, how='left', on='construct2')\n",
    "data2['condition'] = data2['construct'] + '_' + data2['construct2']\n",
    "\n",
    "# Rename far-red channel\n",
    "data2.rename(columns={'SNAP-647-A': 'iRFP-A'}, inplace=True)\n",
    "display(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gate cells\n",
    "gates2 = pd.DataFrame()\n",
    "channel_list = ['mGL-A', 'mRuby2-A']\n",
    "for channel in channel_list:\n",
    "    gates2[channel] = data2[data2['construct']=='GEEC555'].groupby(['exp'])[channel].apply(lambda x: x.quantile(0.999))\n",
    "gates2.reset_index(inplace=True)\n",
    "\n",
    "# Add missing iRFP gate\n",
    "gate_iRFP = 2.5e2\n",
    "gates2['iRFP-A'] = [gate_iRFP]\n",
    "\n",
    "# Indicate which channels are relevant for each experiment\n",
    "gates2.sort_values(['exp'], inplace=True)\n",
    "gates2['marker'] = 'iRFP-A'\n",
    "gates2['output'] = 'mRuby2-A'\n",
    "\n",
    "# Gate data by transfection marker expression\n",
    "data2 = data2.groupby('exp')[data2.columns].apply(lambda x: base.gate_data(x,gates2))\n",
    "data2.reset_index(inplace=True, drop=True)\n",
    "df2 = data2[(data2['expressing']) & (data2['construct']!='UT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin data and calculate statistics\n",
    "by = ['condition','construct','construct2','biorep','exp']\n",
    "df_quantiles2, stats2, _, fits2 = base.calculate_bins_stats(df2, by=by)\n",
    "df_quantiles2.sort_values(['design','ts_kind'], inplace=True)\n",
    "\n",
    "stats2 = stats2.merge(metadata, how='left', on='construct')\n",
    "stats2.sort_values(['design','ts_kind'], inplace=True)\n",
    "stats2 = stats2.merge(metadata_construct2, how='left', on='construct2')\n",
    "\n",
    "fits2 = fits2.merge(metadata, how='left', on='construct')\n",
    "fits2.sort_values(['design','ts_kind'], inplace=True)\n",
    "fits2 = fits2.merge(metadata_construct2, how='left', on='construct2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output range of 5-95 percentile\n",
    "p_5 = df2.groupby(by)[['output']].apply(lambda x: np.percentile(x, 5)).rename('output_5th').reset_index()\n",
    "p_95 = df2.groupby(by)[['output']].apply(lambda x: np.percentile(x, 95)).rename('output_95th').reset_index()\n",
    "stats2 = stats2.merge(p_5, how='left')\n",
    "stats2 = stats2.merge(p_95, how='left')\n",
    "stats2['output_range'] = stats2['output_95th'] - stats2['output_5th']\n",
    "stats2['output_range_log'] = stats2['output_95th'].apply(np.log10) - stats2['output_5th'].apply(np.log10)\n",
    "\n",
    "# fraction within 1 order of magnitude (10x) around median\n",
    "def get_high_low(df):\n",
    "    median = df['output'].median()\n",
    "    return df.loc[(df['output']>(median * 10**(-0.5))) & (df['output']<(median * 10**0.5)), 'output'].count() / df['output'].count()\n",
    "\n",
    "fraction = df2.groupby(by)[df2.columns].apply(get_high_low).rename('fraction_within_10x').reset_index()\n",
    "stats2 = stats2.merge(fraction, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_comb = data2.drop_duplicates('condition')[['construct','construct2','condition']]\n",
    "metadata_comb = metadata_comb.merge(metadata, how='left', on='construct')\n",
    "metadata_comb = metadata_comb.merge(metadata_construct2, how='left', on='construct2')\n",
    "\n",
    "# Create color palette by architecture\n",
    "metadata_comb.loc[metadata_comb['gene']=='1T', 'color'] = base.colors['teal']\n",
    "metadata_comb.loc[metadata_comb['gene']=='2T', 'color'] = base.colors['green']\n",
    "metadata_comb.loc[metadata_comb['gene']=='2V', 'color'] = base.colors['purple']\n",
    "\n",
    "# markers\n",
    "metadata_comb['markers'] = 'X'\n",
    "metadata_comb.loc[metadata_comb['gene']=='1T', 'markers'] = 'o'\n",
    "metadata_comb.loc[metadata_comb['gene']=='2T', 'markers'] = 'D'\n",
    "metadata_comb.loc[metadata_comb['gene']=='2V', 'markers'] = 's'\n",
    "\n",
    "ts_label = {'na': 'base', 'NT': 'OL', 'T': 'CL'}\n",
    "metadata_comb['ts_label'] = metadata_comb['ts_kind'].replace(ts_label)\n",
    "\n",
    "metadata_dict = metadata_comb.set_index('gene').to_dict('dict')\n",
    "gene_palette = metadata_dict['color']\n",
    "gene_markers = metadata_dict['markers']\n",
    "\n",
    "# Create color palette by kind (design)\n",
    "metadata_comb.loc[(metadata_comb['gene']=='1T') & (metadata_comb['design']==2), 'color'] = base.colors['orange']\n",
    "metadata_comb.loc[(metadata_comb['gene']=='1T') & (metadata_comb['design']==3), 'color'] = base.colors['red']\n",
    "\n",
    "metadata_comb['kind'] = metadata_comb['gene'] + '_' + metadata_comb['design'].astype(str)\n",
    "metadata_dict = metadata_comb.set_index('kind').to_dict('dict')\n",
    "kind_palette = metadata_dict['color']\n",
    "kind_markers = metadata_dict['markers']\n",
    "\n",
    "# Create color palette by condition (design)\n",
    "metadata_comb.loc[(metadata_comb['gene']=='2V') & (metadata_comb['construct2_promoter']=='U6'), 'color'] = base.colors['blue']\n",
    "metadata_comb.loc[(metadata_comb['ts_kind']=='NT'), 'color'] = base.colors['gray']\n",
    "metadata_comb.loc[(metadata_comb['ts_kind']=='NT') & (metadata_comb['gene']=='1T') & (metadata_comb['design']==3), \n",
    "                  'color'] = metadata_comb.loc[(metadata_comb['ts_kind']=='NT') & (metadata_comb['gene']=='1T') & \n",
    "                                               (metadata_comb['design']==3), 'color'].apply(base.get_dark_color)\n",
    "metadata_comb.loc[metadata_comb['group'].isin(['base','marker']), 'color'] = 'black'\n",
    "metadata_comb['condition'] = metadata_comb['construct'] + '_' + metadata_comb['construct2']\n",
    "metadata_dict = metadata_comb.set_index('condition').to_dict('dict')\n",
    "condition_palette = metadata_dict['color']\n",
    "condition_markers = metadata_dict['markers']\n",
    "\n",
    "architecture_order = ['1T', '2T', '2V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a second palette for regular tuning\n",
    "metadata2 = base.get_metadata(metadata_path, style='tuning')\n",
    "metadata_dict2 = metadata2.set_index('construct').to_dict('dict')\n",
    "main_palette = metadata_dict2['color']\n",
    "main_markers = metadata_dict2['markers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load PiggyBac data (`data_pb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_path = base_path/'2023.07.18_exp63.3-RC'/'export'\n",
    "\n",
    "plates = pd.DataFrame({\n",
    "    'data_path': [pb_path],\n",
    "    \n",
    "    'yaml_path': [pb_path/'exp63.3_wells2.yaml'],\n",
    "    \n",
    "    'biorep': [1],\n",
    "    \n",
    "    'exp': ['exp63.3-RC']\n",
    "})\n",
    "\n",
    "cache_path = rd.rootdir/'output'/'fig_designs'/'data_pb.gzip'\n",
    "\n",
    "# Load data\n",
    "data_pb = pd.DataFrame()\n",
    "if cache_path.is_file(): data_pb = pd.read_parquet(cache_path)\n",
    "else: \n",
    "    channel_list = ['mCherry-A','mRuby2-A','FSC-A','SSC-A','tagBFP-A','mGL-A']\n",
    "    data_pb = rd.flow.load_groups_with_metadata(plates, columns=channel_list)\n",
    "\n",
    "    # Remove negative channel values\n",
    "    for c in channel_list: data_pb = data_pb[data_pb[c]>0]\n",
    "    \n",
    "    data_pb.dropna(inplace=True)\n",
    "    data_pb.to_parquet(rd.outfile(cache_path))\n",
    "\n",
    "# Add metadata for constructs\n",
    "data_pb = data_pb.merge(metadata, how='left', on='construct')\n",
    "display(data_pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gate cells\n",
    "# Add missing gates (use gates from tuning exp)\n",
    "channel_list = ['mGL-A', 'mRuby2-A']\n",
    "gates.loc[len(gates.index)] = ['exp63.3-RC'] + list(gates.loc[gates['exp']!='exp63.3-RC', channel_list].mean().values) + ['mGL-A','mRuby2-A']  \n",
    "\n",
    "# Gate data by transfection marker expression\n",
    "data_pb = data_pb.groupby('exp')[data_pb.columns].apply(lambda x: base.gate_data(x,gates))\n",
    "data_pb.reset_index(inplace=True, drop=True)\n",
    "df_pb = data_pb[(data_pb['expressing']) & (data_pb['construct']!='UT')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin data and calculate statistics\n",
    "df_quantiles_pb, stats_pb, _, fits_pb = base.calculate_bins_stats(df_pb, num_bins=20)\n",
    "stats_pb = stats_pb.merge(metadata, how='left', on='construct')\n",
    "fits_pb = fits_pb.merge(metadata, how='left', on='construct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from 293T, MEF lenti infections (`data_lenti`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_1 = rd.datadir/'instruments'/'data'/'attune'/'kasey'/'2024.04.05_exp89'/'export'\n",
    "base_path_2 = rd.datadir/'instruments'/'data'/'attune'/'chris'/'2024.06.02-exp95-lenti-miR-iFFL'/'export'\n",
    "plate_list = ['_'.join(x) for x in zip(\n",
    "        ['plate'+str(i) for i in range(1,10)], \n",
    "        (['293T']*3 + ['MEF2A']*3 + ['MEF8A']*3),\n",
    "        ['P9','P14','P15']*3\n",
    "    )]\n",
    "\n",
    "plates = pd.DataFrame({\n",
    "    'data_path': [base_path_1/'293T_control', \n",
    "                  base_path_1/'293T_plate1', base_path_1/'293T_plate2', base_path_1/'293T_plate3',\n",
    "                  base_path_1/'MEF_3_plate1', \n",
    "                  base_path_1/'MEF_4-1_plate1', base_path_1/'MEF_4-1_plate2', base_path_1/'MEF_4-1_plate3'] +\n",
    "                 [base_path_2/p for p in plate_list],\n",
    "    'yaml_path': [base_path_1/'kasey_yaml2'/'plate_control.yaml', \n",
    "                  base_path_1/'kasey_yaml2'/'plate01.yaml', base_path_1/'kasey_yaml2'/'plate02.yaml', base_path_1/'kasey_yaml2'/'plate03.yaml',\n",
    "                  base_path_1/'kasey_yaml2'/'mef_3_plate01.yaml', \n",
    "                  base_path_1/'kasey_yaml2'/'mef_4-1_plate01.yaml', base_path_1/'kasey_yaml2'/'mef_4-1_plate02.yaml', base_path_1/'kasey_yaml2'/'mef_4-1_plate03.yaml'] +\n",
    "                 [base_path_2/(p+'_metadata.yaml') for p in plate_list],\n",
    "})\n",
    "\n",
    "cache_path = rd.rootdir/'output'/'fig_designs'/'data_lenti.gzip'\n",
    "metadata_path = rd.datadir/'projects'/'miR-iFFL'/'plasmids'/'construct-metadata.xlsx'\n",
    "\n",
    "# Load data\n",
    "data_lenti = pd.DataFrame()\n",
    "if cache_path.is_file(): data_lenti = pd.read_parquet(cache_path)\n",
    "else: \n",
    "    channel_list = ['mCherry-A','mRuby2-A','FSC-A','SSC-A','tagBFP-A','mGL-A']\n",
    "    data_lenti = rd.flow.load_groups_with_metadata(plates, columns=channel_list)\n",
    "\n",
    "    # Remove negative channel values\n",
    "    for c in channel_list: data_lenti = data_lenti[data_lenti[c]>0]\n",
    "    \n",
    "    #data.dropna(inplace=True)\n",
    "    data_lenti.to_parquet(rd.outfile(cache_path))\n",
    "\n",
    "# Add metadata for constructs\n",
    "data_lenti = data_lenti.merge(metadata, how='left', on='construct')\n",
    "data_lenti['cell'] = data_lenti['cell_type'].apply(lambda x: x.split('-')[0])\n",
    "data_lenti['exp'] = data_lenti['cell_type'] + '_' + data_lenti['virus_batch']\n",
    "\n",
    "def map_biorep(df):\n",
    "    biorep_map = {val:i for i,val in enumerate(df['exp'].unique())}\n",
    "    d = df.copy()\n",
    "    d['biorep'] = d['exp'].map(biorep_map)\n",
    "    return d\n",
    "\n",
    "data_lenti = data_lenti.groupby('cell')[data_lenti.columns].apply(map_biorep).reset_index(drop=True)\n",
    "display(data_lenti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gate cells\n",
    "gates_lenti = pd.DataFrame()\n",
    "channel_list = ['mGL-A', 'mCherry-A', 'mRuby2-A']\n",
    "for channel in channel_list:\n",
    "    gates_lenti[channel] = data_lenti[(data_lenti['virus_dilution']==0)].groupby(['exp'])[channel].apply(lambda x: x.quantile(0.999))\n",
    "gates_lenti.reset_index(inplace=True)\n",
    "\n",
    "# Add missing gates\n",
    "gates_lenti.loc[len(gates_lenti.index)] = ['293T_P10'] + list(gates_lenti.loc[gates_lenti['exp']=='293T_na', channel_list].mean().values)\n",
    "gates_lenti.loc[len(gates_lenti.index)] = ['293T_P14_'] + list(gates_lenti.loc[gates_lenti['exp']=='293T_na', channel_list].mean().values)\n",
    "gates_lenti.loc[len(gates_lenti.index)] = ['293T_P16'] + list(gates_lenti.loc[gates_lenti['exp']=='293T_na', channel_list].mean().values) \n",
    "gates_lenti.loc[len(gates_lenti.index)] = ['MEF-3_P10'] + list(gates_lenti.loc[gates_lenti['exp'].str.contains('MEF'), channel_list].mean().values)\n",
    "gates_lenti.loc[len(gates_lenti.index)] = ['MEF-4-1_P10'] + list(gates_lenti.loc[gates_lenti['exp'].str.contains('MEF'), channel_list].mean().values)\n",
    "gates_lenti.loc[len(gates_lenti.index)] = ['MEF-4-1_P14'] + list(gates_lenti.loc[gates_lenti['exp'].str.contains('MEF'), channel_list].mean().values)\n",
    "gates_lenti.loc[len(gates_lenti.index)] = ['MEF-4-1_P16'] + list(gates_lenti.loc[gates_lenti['exp'].str.contains('MEF'), channel_list].mean().values)\n",
    "\n",
    "# Indicate which channels are relevant for each experiment\n",
    "gates_lenti.sort_values(['exp'], inplace=True)\n",
    "gates_lenti['marker'] = 'mGL-A'\n",
    "gates_lenti['output'] = 'mRuby2-A'\n",
    "\n",
    "# Gate data by marker expression\n",
    "data_lenti = data_lenti.groupby(['cell_type','virus_batch'])[data_lenti.columns].apply(lambda x: base.gate_data(x,gates_lenti))\n",
    "data_lenti.reset_index(inplace=True, drop=True)\n",
    "df_lenti = data_lenti[(data_lenti['expressing']) & (data_lenti['virus_dilution']!=0)]\n",
    "\n",
    "# Since there is no marker-only condition, save the output expression stats for untransduced cells\n",
    "baseline_df = data_lenti[(data_lenti['virus_dilution']==0)].groupby(['exp','cell'])['output'].apply(sp.stats.gmean).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin data and calculate statistics\n",
    "df_lenti['output'] = df_lenti['output'].astype(float)\n",
    "df_lenti['marker'] = df_lenti['marker'].astype(float)\n",
    "df_quantiles_lenti, stats_lenti, _, fits_lenti = base.calculate_bins_stats(df_lenti, by=['exp','cell','biorep','construct','dox','virus_dilution'], num_bins=20)\n",
    "stats_lenti = stats_lenti.merge(metadata, how='left', on='construct')\n",
    "fits_lenti = fits_lenti.merge(metadata, how='left', on='construct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_size = base.font_sizes['base_size']\n",
    "smaller_size = base.font_sizes['smaller_size']\n",
    "\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('paper', font_scale=1.0, rc={'font.size': base_size, 'font.family': 'sans-serif', 'font.sans-serif':['Arial']})\n",
    "plt.rcParams.update({'axes.titlesize': base_size, 'axes.labelsize': base_size, 'xtick.labelsize': smaller_size, 'ytick.labelsize': smaller_size,\n",
    "                     'pdf.fonttype': 42, \n",
    "                     'ytick.major.size': 3, 'xtick.major.size': 3, 'ytick.minor.size': 2, 'ytick.major.pad': 2, 'xtick.major.pad': 2, \n",
    "                     'lines.linewidth': 1,\n",
    "                     'axes.spines.right': False, 'axes.spines.top': False, 'axes.labelpad': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the overall figure, gridspec, and add subfigure labels\n",
    "fig = plt.figure(figsize=(6.8504,9.75))\n",
    "fig_gridspec = matplotlib.gridspec.GridSpec(6, 6, figure=fig,\n",
    "    wspace=0.4, hspace=0.4, height_ratios=(1.75,1.5,1.5,2,1.5,1.5),)\n",
    "subfigures = {\n",
    "    'A': fig.add_subfigure(fig_gridspec[0,:3]),\n",
    "    'B': fig.add_subfigure(fig_gridspec[0,3:]),\n",
    "    'C': fig.add_subfigure(fig_gridspec[1,:3]),\n",
    "    'D': fig.add_subfigure(fig_gridspec[1,3:]),\n",
    "    'E': fig.add_subfigure(fig_gridspec[2,:3]),\n",
    "    'F': fig.add_subfigure(fig_gridspec[2,3:]),\n",
    "    'G': fig.add_subfigure(fig_gridspec[3,:2]),\n",
    "    'H': fig.add_subfigure(fig_gridspec[3,2:]),\n",
    "    'I': fig.add_subfigure(fig_gridspec[4,:]),\n",
    "    'J': fig.add_subfigure(fig_gridspec[5,:4]),\n",
    "    'K': fig.add_subfigure(fig_gridspec[5,4:]),\n",
    "}\n",
    "for label, subfig in subfigures.items():\n",
    "    subfig.add_artist(matplotlib.text.Text(x=0, y=1, text=f'{label}', fontsize=base.font_sizes['subpanel_label'], \n",
    "                                           fontweight='bold', verticalalignment='top',transform=subfig.transSubfigure))\n",
    "scatter_kwargs = dict(s=4, jitter=0.2, linewidth=0.5, edgecolor='white')\n",
    "xlim = (2e2,6e4)\n",
    "ylim = (2e1,1e5)\n",
    "\n",
    "fig_path = output_path/'fig_designs-supp.pdf'\n",
    "fig.savefig(rd.outfile(fig_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfig = subfigures['A']\n",
    "rd.plot.adjust_subplot_margins_inches(subfig, left=0.4, bottom=0.5, top=0.65, right=0.15)\n",
    "axes = subfig.subplots(1,3, gridspec_kw=dict(width_ratios=(1,1,1), wspace=0.35))\n",
    "\n",
    "# EF1a miR controls\n",
    "miR_order = ['none', 'miR.FF5', 'miR.FF4', 'miRE.FF5', 'miRE.FF4',]\n",
    "plot_df = stats[((((stats['group']=='miR')) & (stats['miR_loc']=='UTR')) | (stats['group']=='base')) &\n",
    "                (stats['promoter']=='EF1a')].copy()\n",
    "plot_df['miR'] = plot_df['miR'].astype(pd.api.types.CategoricalDtype(categories=miR_order, ordered=True))\n",
    "plot_df2 = fits[((((fits['group']=='miR')) & (fits['miR_loc']=='UTR')) | (fits['group']=='base')) &\n",
    "                (fits['promoter']=='EF1a')].copy()\n",
    "plot_df2['miR'] = plot_df2['miR'].astype(pd.api.types.CategoricalDtype(categories=miR_order, ordered=True))\n",
    "xlim = (-0.5, len(plot_df['construct'].unique())-0.5)\n",
    "ylim = (2e1,8e4)\n",
    "\n",
    "# stat gmean\n",
    "ax = axes[0]\n",
    "for construct, group in plot_df.groupby('construct'):\n",
    "    sns.stripplot(data=group, x='miR', y='output_gmean', hue='construct', palette=main_palette,\n",
    "                    legend=False, ax=ax, marker=main_markers[construct], **scatter_kwargs)\n",
    "ax.set(title='Mean', xlim=xlim, xlabel='', ylabel='', yscale='log', ylim=ylim)\n",
    "marker_baseline = stats.loc[(stats['group']=='marker'), 'output_gmean'].mean()\n",
    "ax.axhline(marker_baseline, color='black', ls=':')\n",
    "\n",
    "# stat std\n",
    "ax = axes[1]\n",
    "for construct, group in plot_df.groupby('construct'):\n",
    "    sns.stripplot(data=group, x='miR', y='output_std', hue='construct', palette=main_palette,\n",
    "                    legend=False, ax=ax, marker=main_markers[construct], **scatter_kwargs)\n",
    "ax.set(title='Std.', xlim=xlim, xlabel='', ylabel='', yscale='log', ylim=ylim)\n",
    "\n",
    "# slope\n",
    "ax = axes[2]\n",
    "for construct, group in plot_df2.groupby('construct'):\n",
    "    sns.stripplot(data=group, x='miR', y='slope', hue='construct', palette=main_palette,\n",
    "                    legend=False, ax=ax, marker=main_markers[construct], s=4, jitter=0.1, linewidth=0.5, edgecolor='white')\n",
    "ax.set(title='Slope', xlim=xlim, xlabel='', ylim=(0,1.2), ylabel='',\n",
    "       yticks=[0,0.25,0.5,0.75,1], yticklabels=['0.0','','0.5','','1.0'])\n",
    "marker_baseline = fits.loc[(fits['group']=='marker'), 'slope'].mean()\n",
    "ax.axhline(marker_baseline, color='black', ls=':')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xticklabels([l.get_text().replace('.','-') for l in ax.get_xticklabels()], rotation=45, ha='right')\n",
    "    sns.despine(ax=ax)\n",
    "    ax.minorticks_off()\n",
    "\n",
    "fig.savefig(rd.outfile(fig_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfig = subfigures['B']\n",
    "rd.plot.adjust_subplot_margins_inches(subfig, left=0.4, bottom=0.5, top=0.65, right=0.15)\n",
    "axes = subfig.subplots(1,3, gridspec_kw=dict(width_ratios=(1,1,1), wspace=0.35))\n",
    "\n",
    "# EF1a miR controls\n",
    "ts_order = ['none','FF3x1','FF4x1','FF5x1','FF6x1']\n",
    "plot_df = stats[((((stats['group']=='ts5')) & (stats['ts_num']==1)) | (stats['group']=='base')) &\n",
    "                (stats['promoter']=='EF1a')].copy()\n",
    "plot_df['ts'] = plot_df['ts'].astype(pd.api.types.CategoricalDtype(categories=ts_order, ordered=True))\n",
    "plot_df2 = fits[((((fits['group']=='ts5')) & (fits['ts_num']==1)) | (fits['group']=='base')) &\n",
    "                (fits['promoter']=='EF1a')].copy()\n",
    "plot_df2['ts'] = plot_df2['ts'].astype(pd.api.types.CategoricalDtype(categories=ts_order, ordered=True))\n",
    "xlim = (-0.5, len(plot_df['ts'].unique())-0.5)\n",
    "\n",
    "# stat gmean\n",
    "ax = axes[0]\n",
    "for construct, group in plot_df.groupby('construct'):\n",
    "    sns.stripplot(data=group, x='ts', y='output_gmean', hue='construct', palette=main_palette,\n",
    "                    legend=False, ax=ax, marker=main_markers[construct], **scatter_kwargs)\n",
    "ax.set(title='Mean', xlim=xlim, xlabel='', ylabel='', yscale='log', ylim=ylim)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "marker_baseline = stats.loc[(stats['group']=='marker'), 'output_gmean'].mean()\n",
    "ax.axhline(marker_baseline, color='black', ls=':')\n",
    "\n",
    "# stat std\n",
    "ax = axes[1]\n",
    "for construct, group in plot_df.groupby('construct'):\n",
    "    sns.stripplot(data=group, x='ts', y='output_std', hue='construct', palette=main_palette,\n",
    "                    legend=False, ax=ax, marker=main_markers[construct], **scatter_kwargs)\n",
    "ax.set(title='Std.', xlim=xlim, xlabel='', ylabel='', yscale='log', ylim=ylim)\n",
    "\n",
    "# slope\n",
    "ax = axes[2]\n",
    "for construct, group in plot_df2.groupby('construct'):\n",
    "    sns.stripplot(data=group, x='ts', y='slope', hue='construct', palette=main_palette,\n",
    "                    legend=False, ax=ax, marker=main_markers[construct], **scatter_kwargs)\n",
    "ax.set(title='Slope', xlim=xlim, xlabel='', ylim=(0,1.2), ylabel='',\n",
    "       yticks=[0,0.25,0.5,0.75,1], yticklabels=['0.0','','0.5','','1.0'])\n",
    "marker_baseline = fits.loc[(fits['group']=='marker'), 'slope'].mean()\n",
    "ax.axhline(marker_baseline, color='black', ls=':')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    sns.despine(ax=ax)\n",
    "    ax.minorticks_off()\n",
    "\n",
    "fig.savefig(rd.outfile(fig_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfig = subfigures['C']\n",
    "rd.plot.adjust_subplot_margins_inches(subfig, left=0.7, bottom=0.4, top=0.35, right=0.15)\n",
    "axes = subfig.subplots(1,3, gridspec_kw=dict(width_ratios=(1,1,1), wspace=0.45))\n",
    "\n",
    "plot_df1 = stats[(stats['miR']=='miR.FF4') & (stats['group']=='controller') & (stats['ts_num']==1) &\n",
    "                (stats['promoter']=='EF1a')]\n",
    "plot_df2 = stats_pb\n",
    "plot_df3 = stats_lenti[stats_lenti['group'].isin(['controller','base']) & (stats_lenti['dox']==1000) & (stats_lenti['virus_dilution']==1) & \n",
    "                      (stats_lenti['cell']=='293T') & ~((stats_lenti['biorep']<4) & (stats_lenti['design']==3))]\n",
    "plot_df_list = {'Transfection': plot_df1, 'PiggyBac': plot_df2, 'Lentivirus': plot_df3,}\n",
    "\n",
    "for ax, (name, plot_df) in zip(axes, plot_df_list.items()):\n",
    "    for construct, group in plot_df.groupby('construct'):\n",
    "        sns.stripplot(data=group, x='design', y='output_std', hue='construct', palette=designs_palette,\n",
    "                        legend=False, ax=ax, marker=designs_markers[construct], **scatter_kwargs)\n",
    "    ax.set(title=name, xlim=(-0.5, len(plot_df['design'].unique())-0.5), xlabel='', ylabel='', yscale='log',)\n",
    "\n",
    "axes[0].set(xlabel='design',ylabel='Standard deviation')\n",
    "\n",
    "fig.savefig(rd.outfile(fig_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def designs_stats_plots(axes, plot_df, plot_df2):\n",
    "\n",
    "    xlim = (-0.5, len(plot_df['design'].unique())-0.5)\n",
    "\n",
    "    # stat gmean\n",
    "    ax = axes[0]\n",
    "    for construct, group in plot_df.groupby('construct'):\n",
    "        sns.stripplot(data=group, x='design', y='output_gmean', hue='construct', palette=designs_palette,\n",
    "                        legend=False, ax=ax, marker=designs_markers[construct], **scatter_kwargs)\n",
    "    ax.set(title='Mean', xlim=xlim, xlabel='', ylabel='', yscale='log',)\n",
    "    marker_baseline = stats.loc[(stats['group']=='marker'), 'output_gmean'].mean()\n",
    "    ax.axhline(marker_baseline, color='black', ls=':')\n",
    "    ax.minorticks_off()\n",
    "\n",
    "    # stat std\n",
    "    ax = axes[1]\n",
    "    for construct, group in plot_df.groupby('construct'):\n",
    "        sns.stripplot(data=group, x='design', y='output_std', hue='construct', palette=designs_palette,\n",
    "                        legend=False, ax=ax, marker=designs_markers[construct], **scatter_kwargs)\n",
    "    ax.set(title='Std.', xlim=xlim, xlabel='design', ylabel='', yscale='log',)\n",
    "\n",
    "    # slope\n",
    "    ax = axes[2]\n",
    "    for construct, group in plot_df2.groupby('construct'):\n",
    "        sns.stripplot(data=group, x='design', y='slope', hue='construct', palette=designs_palette,\n",
    "                        legend=False, ax=ax, marker=designs_markers[construct], **scatter_kwargs)\n",
    "    ax.set(title='Slope', xlim=xlim, xlabel='', ylabel='', ylim=(0,1.2),\n",
    "        yticks=[0,0.25,0.5,0.75,1], yticklabels=['0.0','','0.5','','1.0'])\n",
    "    marker_baseline = fits.loc[(fits['group']=='marker'), 'slope'].mean()\n",
    "    ax.axhline(marker_baseline, color='black', ls=':')\n",
    "\n",
    "    for ax in axes: sns.despine(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfig = subfigures['D']\n",
    "rd.plot.adjust_subplot_margins_inches(subfig, left=0.7, bottom=0.4, top=0.35, right=0.15)\n",
    "axes = subfig.subplots(1,3, gridspec_kw=dict(width_ratios=(1,1,1), wspace=0.45))\n",
    "\n",
    "plot_df = stats[(stats['miR']=='miR.FF4') & (stats['group']=='controller') & (stats['ts_num']==1) &\n",
    "                       (stats['promoter']=='EF1a')]\n",
    "plot_df2 = fits[(fits['miR']=='miR.FF4') & (fits['group']=='controller') & (fits['ts_num']==1) &\n",
    "                       (fits['promoter']=='EF1a')]\n",
    "\n",
    "designs_stats_plots(axes, plot_df, plot_df2)\n",
    "\n",
    "fig.savefig(rd.outfile(fig_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfig = subfigures['E']\n",
    "rd.plot.adjust_subplot_margins_inches(subfig, left=0.7, bottom=0.4, top=0.35, right=0.15)\n",
    "axes = subfig.subplots(1,3, gridspec_kw=dict(width_ratios=(1,1,1), wspace=0.45))\n",
    "\n",
    "plot_df = stats[(stats['miR']=='miR.FF5') & (stats['group']=='controller') & (stats['ts_num']==1) & \n",
    "                       (stats['ts'].isin(['FF4x1','FF5x1','FF6x1'])) & (stats['promoter']=='EF1a')]\n",
    "plot_df2 = fits[(fits['miR']=='miR.FF5') & (fits['group']=='controller') & (fits['ts_num']==1) &\n",
    "                       (fits['ts'].isin(['FF4x1','FF5x1','FF6x1'])) & (fits['promoter']=='EF1a')]\n",
    "\n",
    "designs_stats_plots(axes, plot_df, plot_df2)\n",
    "\n",
    "fig.savefig(rd.outfile(fig_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfig = subfigures['F']\n",
    "rd.plot.adjust_subplot_margins_inches(subfig, left=0.7, bottom=0.4, top=0.35, right=0.15)\n",
    "axes = subfig.subplots(1,3, gridspec_kw=dict(width_ratios=(1,1,1), wspace=0.45))\n",
    "\n",
    "plot_df = stats[(stats['miR']=='miRE.FF5') & (stats['group']=='controller') & (stats['ts_num']==1) &\n",
    "                       (stats['promoter']=='EF1a')]\n",
    "plot_df2 = fits[(fits['miR']=='miRE.FF5') & (fits['group']=='controller') & (fits['ts_num']==1) &\n",
    "                       (fits['promoter']=='EF1a')]\n",
    "\n",
    "designs_stats_plots(axes, plot_df, plot_df2)\n",
    "\n",
    "fig.savefig(rd.outfile(fig_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two-gene architectures with 5'UTR target sites\n",
    "stats_subset = stats2[((stats2['gene']=='1T') & (stats2['design']>1) & (stats2['group']=='controller')) |\n",
    "                ((stats2['gene']=='2T') & (stats2['group']=='dual') & (stats2['ts_loc']=='5\\'')) |\n",
    "                ((stats2['gene']=='2V') & (stats2['group']=='ts5')) |\n",
    "                (stats2['group']=='base')].copy()\n",
    "stats_subset.sort_values(['gene','construct2_promoter','group','ts_kind'], inplace=True)\n",
    "fits_subset = fits2[((fits2['gene']=='1T') & (fits2['design']>1) & (fits2['group']=='controller')) |\n",
    "                ((fits2['gene']=='2T') & (fits2['group']=='dual') & (fits2['ts_loc']=='5\\'')) |\n",
    "                ((fits2['gene']=='2V') & (fits2['group']=='ts5')) |\n",
    "                (fits2['group']=='base')].copy()\n",
    "fits_subset.sort_values(['gene','construct2_promoter','group','ts_kind'], inplace=True)\n",
    "df_quantiles_subset = df_quantiles2[(((df_quantiles2['gene']=='1T') & (df_quantiles2['design']>1) & (df_quantiles2['group']=='controller')) |\n",
    "                        ((df_quantiles2['gene']=='2T') & (df_quantiles2['group']=='dual')) |\n",
    "                        ((df_quantiles2['gene']=='2V') & (df_quantiles2['group']=='ts5')) |\n",
    "                        (df_quantiles2['group']=='base'))].copy()\n",
    "df_quantiles_subset.sort_values(['gene','construct2_promoter','group','ts_kind'], inplace=True)\n",
    "\n",
    "# shift xticks to add more space between architecture groups\n",
    "buffer = 0.6\n",
    "gene_order = ['1T', '2T', '2V']\n",
    "xtick_locs = [0,1,2,3,4, 5+buffer,6+buffer, 7+buffer*2,8+buffer*2,9+buffer*2, 10+buffer*3,11+buffer*3,12+buffer*3,]\n",
    "\n",
    "condition_loc = {k:v for k,v in zip(stats_subset['condition'].unique(), xtick_locs)}\n",
    "stats_subset['condition_loc'] = stats_subset['condition'].replace(condition_loc)\n",
    "\n",
    "condition_loc = {k:v for k,v in zip(fits_subset['condition'].unique(), xtick_locs)}\n",
    "fits_subset['condition_loc'] = fits_subset['condition'].replace(condition_loc)\n",
    "\n",
    "metadata_comb['condition_loc'] = metadata_comb['condition'].map(condition_loc)\n",
    "m = metadata_comb.dropna()\n",
    "m['condition_loc'] = m['condition_loc'].astype(str)\n",
    "\n",
    "xlim_adjusted = (-0.5, len(stats_subset['condition'].unique())-0.5+buffer*(len(gene_order)))\n",
    "scatter_kwargs2 = dict(s=4, jitter=0.1, linewidth=0.5, edgecolor='white', native_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfig = subfigures['H']\n",
    "rd.plot.adjust_subplot_margins_inches(subfig, left=0.4, bottom=0.55, top=0.35, right=0.1)\n",
    "axes = subfig.subplots(1,3, gridspec_kw=dict(width_ratios=(1,1,1), wspace=0.3))\n",
    "\n",
    "plot_df = stats_subset\n",
    "plot_df2 = fits_subset\n",
    "\n",
    "# stat gmean\n",
    "ax = axes[0]\n",
    "for construct, group in plot_df.groupby('condition', sort=False):\n",
    "    sns.stripplot(data=group, x='condition_loc', y='output_gmean', hue='condition', palette=condition_palette,\n",
    "                    legend=False, ax=ax, marker=condition_markers[construct], **scatter_kwargs2)\n",
    "ax.set(title='Mean', xlim=xlim_adjusted, xlabel='', ylabel='', yscale='log', xticks=xtick_locs)\n",
    "marker_baseline = stats2.loc[(stats2['group']=='marker'), 'output_gmean'].mean()\n",
    "ax.axhline(marker_baseline, color='black', ls=':')\n",
    "\n",
    "# stat std\n",
    "ax = axes[1]\n",
    "for construct, group in plot_df.groupby('condition', sort=False):\n",
    "    sns.stripplot(data=group, x='condition_loc', y='output_std', hue='condition', palette=condition_palette,\n",
    "                    legend=False, ax=ax, marker=condition_markers[construct], **scatter_kwargs2)\n",
    "ax.set(title='Standard deviation', xlim=xlim_adjusted, xlabel='', ylabel='', yscale='log', xticks=xtick_locs)\n",
    "\n",
    "# slope\n",
    "ax = axes[2]\n",
    "for construct, group in plot_df2.groupby('condition', sort=False):\n",
    "    sns.stripplot(data=group, x='condition_loc', y='slope', hue='condition', palette=condition_palette,\n",
    "                    legend=False, ax=ax, marker=condition_markers[construct], **scatter_kwargs2)\n",
    "\n",
    "ax.set(title='Slope', xlim=xlim_adjusted, xlabel='', ylabel='', xticks=xtick_locs,)\n",
    "marker_baseline = fits2.loc[(fits2['group']=='marker'), 'slope'].mean()\n",
    "ax.axhline(marker_baseline, color='black', ls=':')\n",
    "\n",
    "for i,ax in enumerate(axes):\n",
    "    yloc = -6\n",
    "    ax.axvspan(4.5+buffer/2, 6.5+buffer*1.5, color=base.get_light_color(base.colors['gray']), alpha=0.2,)\n",
    "    ax.axvspan(9.5+buffer*2.5, 12.5+buffer*3.5, color=base.get_light_color(base.colors['gray']), alpha=0.2,)\n",
    "    ax.annotate(architecture_order[0], (2,yloc), xycoords=('data','axes points'), ha='center', va='top', ma='center', fontsize=smaller_size)\n",
    "    ax.annotate(architecture_order[1], (5.5+buffer,yloc), xycoords=('data','axes points'), ha='center', va='top', ma='center', fontsize=smaller_size)\n",
    "    ax.annotate('2V\\nEF1a', (8+buffer*2,yloc), xycoords=('data','axes points'), ha='center', va='top', ma='center', fontsize=smaller_size)\n",
    "    ax.annotate('2V\\nU6', (11+buffer*3,yloc), xycoords=('data','axes points'), ha='center', va='top', ma='center', fontsize=smaller_size)\n",
    "    ax.set_xticklabels(['']*len(ax.get_xticklabels()))\n",
    "    sns.despine(ax=ax)\n",
    "\n",
    "fig.savefig(rd.outfile(fig_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfig = subfigures['J']\n",
    "rd.plot.adjust_subplot_margins_inches(subfig, left=0.4, bottom=0.45, top=0.35, right=0.15)\n",
    "axes = subfig.subplots(1,3, gridspec_kw=dict(width_ratios=(1,1,1), wspace=0.3))\n",
    "\n",
    "# iPSC controls\n",
    "group_order = ['base','miR','ts3','ts5']\n",
    "plot_df = stats_lenti[~stats_lenti['group'].isin(['controller','marker']) & (stats_lenti['cell']=='293T') &\n",
    "                      (stats_lenti['dox']==1000) & (stats_lenti['virus_dilution']==1)].copy()\n",
    "plot_df['group'] = plot_df['group'].astype(pd.api.types.CategoricalDtype(categories=group_order, ordered=True))\n",
    "plot_df.sort_values(['group','ts'], inplace=True)\n",
    "\n",
    "plot_df2 = fits_lenti[~fits_lenti['group'].isin(['controller','marker']) & (fits_lenti['cell']=='293T') & \n",
    "                      (fits_lenti['dox']==1000) & (fits_lenti['virus_dilution']==1)].copy()\n",
    "plot_df2['group'] = plot_df2['group'].astype(pd.api.types.CategoricalDtype(categories=group_order, ordered=True))\n",
    "plot_df2.sort_values(['group','ts'], inplace=True)\n",
    "\n",
    "# shift xticks to add more space between promoter groups\n",
    "buffer = 0.6\n",
    "num_groups = 3\n",
    "xtick_locs = [0, 1+buffer, 2+buffer] + [i+buffer*2 for i in range(3,7)]\n",
    "construct_loc = {k:v for k,v in zip(plot_df['construct'].unique(), xtick_locs)}\n",
    "plot_df['construct_loc'] = plot_df['construct'].replace(construct_loc)\n",
    "construct_loc = {k:v for k,v in zip(plot_df2['construct'].unique(), xtick_locs)}\n",
    "plot_df2['construct_loc'] = plot_df2['construct'].replace(construct_loc)\n",
    "metadata['construct_loc'] = metadata['construct'].map(construct_loc)\n",
    "m = metadata.dropna()\n",
    "m['construct_loc'] = m['construct_loc'].astype(str)\n",
    "scatter_kwargs2 = dict(s=4, jitter=0.3, linewidth=0.5, edgecolor='white', native_scale=True)\n",
    "xlim = (-0.5, plot_df['construct_loc'].max()+0.5)\n",
    "\n",
    "# adjust markers\n",
    "m.loc[(m['miR_loc']=='CDS') | (m['ts_loc']=='3\\''), 'markers'] = 'D'\n",
    "m_dict = m.set_index('construct').to_dict('dict')\n",
    "comb_markers = m_dict['markers']\n",
    "\n",
    "# make xticklabels\n",
    "def get_label(df):\n",
    "    group = df['group'].unique()[0]\n",
    "    d = df.copy()\n",
    "    col_map = {'base': 'group', 'miR': 'miR', 'ts3': 'ts', 'ts5': 'ts'}\n",
    "    d['label'] = d[col_map[group]]\n",
    "    return d\n",
    "\n",
    "m = m.groupby('group')[m.columns].apply(get_label).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# stat gmean\n",
    "ax = axes[0]\n",
    "for construct, group in plot_df.groupby('construct', sort=False):\n",
    "    sns.stripplot(data=group, x='construct_loc', y='output_gmean', hue='construct', palette=main_palette,\n",
    "                    legend=False, ax=ax, marker=comb_markers[construct], **scatter_kwargs2)\n",
    "ax.set(title='Mean', xlim=xlim, xlabel='', ylabel='', yscale='log', xticks=xtick_locs,)\n",
    "baseline = baseline_df.loc[baseline_df['cell']=='293T', 'output'].mean()\n",
    "ax.axhline(baseline, color='black', ls=':')\n",
    "\n",
    "# stat std\n",
    "ax = axes[1]\n",
    "for construct, group in plot_df.groupby('construct', sort=False):\n",
    "    sns.stripplot(data=group, x='construct_loc', y='output_std', hue='construct', palette=main_palette,\n",
    "                    legend=False, ax=ax, marker=comb_markers[construct], **scatter_kwargs2)\n",
    "ax.set(title='Standard deviation', xlim=xlim, xlabel='', ylabel='', yscale='log', xticks=xtick_locs,)\n",
    "\n",
    "# slope\n",
    "ax = axes[2]\n",
    "for construct, group in plot_df2.groupby('construct', sort=False):\n",
    "    sns.stripplot(data=group, x='construct_loc', y='slope', hue='construct', palette=main_palette,\n",
    "                    legend=False, ax=ax, marker=comb_markers[construct], **scatter_kwargs2)\n",
    "ax.set(title='Slope', xlim=xlim, xlabel='', ylim=(0,1.2), ylabel='', xticks=xtick_locs,\n",
    "       yticks=[0,0.25,0.5,0.75,1], yticklabels=['0.0','','0.5','','1.0'])\n",
    "\n",
    "for ax in axes:\n",
    "    sns.despine(ax=ax)\n",
    "\n",
    "    # add shaded region for miR-only constructs\n",
    "    span1 = (xtick_locs[0]+(xtick_locs[1]-xtick_locs[0])/2, xtick_locs[2]+(xtick_locs[3]-xtick_locs[2])/2,)\n",
    "    ax.axvspan(*span1, color=base.get_light_color(base.colors['gray']), alpha=0.2,)\n",
    "    rd.plot.generate_xticklabels(m.drop_duplicates('construct_loc'), 'construct_loc', ['label'], annotate=False, ax=ax)\n",
    "    ax.set_xticklabels([l.get_text().replace('.','-') for l in ax.get_xticklabels()], rotation=45, ha='right')\n",
    "    ax.yaxis.set_minor_formatter(plt.NullFormatter())\n",
    "\n",
    "fig.savefig(rd.outfile(fig_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subfig = subfigures['K']\n",
    "rd.plot.adjust_subplot_margins_inches(subfig, left=0.5, bottom=0.45, top=0.35, right=0.1)\n",
    "axes = subfig.subplots(1,2, gridspec_kw=dict(width_ratios=(1,1), wspace=0.5))\n",
    "\n",
    "plot_df = stats_lenti[(stats_lenti['group'].isin(['controller','base'])) & (stats_lenti['cell']=='293T') &\n",
    "                      (stats_lenti['dox']==0) & (stats_lenti['virus_dilution']==1)].copy()\n",
    "plot_df2 = fits_lenti[(fits_lenti['group'].isin(['controller','base'])) & (fits_lenti['cell']=='293T') &\n",
    "                      (fits_lenti['dox']==0) & (fits_lenti['virus_dilution']==1)].copy()\n",
    "xlim = (-0.5, len(plot_df['design'].unique())-0.5)\n",
    "\n",
    "# stat gmean\n",
    "ax = axes[0]\n",
    "for construct, group in plot_df.groupby('construct'):\n",
    "    sns.stripplot(data=group, x='design', y='output_gmean', hue='construct', palette=designs_palette,\n",
    "                    legend=False, ax=ax, marker=designs_markers[construct], **scatter_kwargs)\n",
    "ax.set(title='Mean', xlim=xlim, xlabel='design', ylabel='', yscale='log', ylim=(2e1,6e1))\n",
    "baseline = baseline_df.loc[baseline_df['cell']=='293T', 'output'].mean()\n",
    "ax.axhline(baseline, color='black', ls=':')\n",
    "\n",
    "# slope\n",
    "ax = axes[1]\n",
    "for construct, group in plot_df2.groupby('construct'):\n",
    "    sns.stripplot(data=group, x='design', y='slope', hue='construct', palette=designs_palette,\n",
    "                    legend=False, ax=ax, marker=designs_markers[construct], **scatter_kwargs)\n",
    "ax.set(title='Slope', xlim=xlim, xlabel='design', ylabel='', ylim=(-0.2,0.2))\n",
    "ax.axhline(0, color='black', ls=':')\n",
    "\n",
    "fig.savefig(rd.outfile(fig_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
